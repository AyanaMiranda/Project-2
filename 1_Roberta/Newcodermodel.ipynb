{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "964c9180-6e36-4e2b-bf3e-46f2ee4dd86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\philk\\AppData\\Local\\Temp\\ipykernel_70596\\2481443108.py:11: DtypeWarning: Columns (17,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data_cleaned = pd.read_csv('./clean-data/2017-fCC-New-Coders-Survey-Data.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>AttendedBootcamp</th>\n",
       "      <th>BootcampFinish</th>\n",
       "      <th>BootcampLoanYesNo</th>\n",
       "      <th>BootcampName</th>\n",
       "      <th>BootcampRecommend</th>\n",
       "      <th>ChildrenNumber</th>\n",
       "      <th>CityPopulation</th>\n",
       "      <th>CodeEventConferences</th>\n",
       "      <th>CodeEventDjangoGirls</th>\n",
       "      <th>...</th>\n",
       "      <th>YouTubeFCC</th>\n",
       "      <th>YouTubeFunFunFunction</th>\n",
       "      <th>YouTubeGoogleDev</th>\n",
       "      <th>YouTubeLearnCode</th>\n",
       "      <th>YouTubeLevelUpTuts</th>\n",
       "      <th>YouTubeMIT</th>\n",
       "      <th>YouTubeMozillaHacks</th>\n",
       "      <th>YouTubeOther</th>\n",
       "      <th>YouTubeSimplilearn</th>\n",
       "      <th>YouTubeTheNewBoston</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>more than 1 million</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>less than 100,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>more than 1 million</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>between 100,000 and 1 million</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>between 100,000 and 1 million</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  AttendedBootcamp  BootcampFinish  BootcampLoanYesNo BootcampName  \\\n",
       "0  27.0               0.0             NaN                NaN          NaN   \n",
       "1  34.0               0.0             NaN                NaN          NaN   \n",
       "2  21.0               0.0             NaN                NaN          NaN   \n",
       "3  26.0               0.0             NaN                NaN          NaN   \n",
       "4  20.0               0.0             NaN                NaN          NaN   \n",
       "\n",
       "   BootcampRecommend  ChildrenNumber                 CityPopulation  \\\n",
       "0                NaN             NaN            more than 1 million   \n",
       "1                NaN             NaN              less than 100,000   \n",
       "2                NaN             NaN            more than 1 million   \n",
       "3                NaN             NaN  between 100,000 and 1 million   \n",
       "4                NaN             NaN  between 100,000 and 1 million   \n",
       "\n",
       "   CodeEventConferences  CodeEventDjangoGirls  ...  YouTubeFCC  \\\n",
       "0                   NaN                   NaN  ...         NaN   \n",
       "1                   NaN                   NaN  ...         1.0   \n",
       "2                   NaN                   NaN  ...         NaN   \n",
       "3                   NaN                   NaN  ...         1.0   \n",
       "4                   NaN                   NaN  ...         NaN   \n",
       "\n",
       "   YouTubeFunFunFunction  YouTubeGoogleDev  YouTubeLearnCode  \\\n",
       "0                    NaN               NaN               NaN   \n",
       "1                    NaN               NaN               NaN   \n",
       "2                    NaN               NaN               1.0   \n",
       "3                    1.0               NaN               NaN   \n",
       "4                    NaN               NaN               NaN   \n",
       "\n",
       "   YouTubeLevelUpTuts  YouTubeMIT  YouTubeMozillaHacks YouTubeOther  \\\n",
       "0                 NaN         NaN                  NaN          NaN   \n",
       "1                 NaN         NaN                  NaN          NaN   \n",
       "2                 1.0         NaN                  NaN          NaN   \n",
       "3                 1.0         NaN                  NaN          NaN   \n",
       "4                 NaN         NaN                  NaN          NaN   \n",
       "\n",
       "   YouTubeSimplilearn  YouTubeTheNewBoston  \n",
       "0                 NaN                  NaN  \n",
       "1                 NaN                  NaN  \n",
       "2                 NaN                  NaN  \n",
       "3                 NaN                  NaN  \n",
       "4                 NaN                  NaN  \n",
       "\n",
       "[5 rows x 136 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_cleaned = pd.read_csv('./clean-data/2017-fCC-New-Coders-Survey-Data.csv')\n",
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b81d378d-d32b-489f-8c58-9bb2d0277bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18175 entries, 0 to 18174\n",
      "Columns: 136 entries, Age to YouTubeTheNewBoston\n",
      "dtypes: float64(105), object(31)\n",
      "memory usage: 18.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data_cleaned.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a92d086-483f-4007-a36c-8341423c77f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                    float64\n",
       "AttendedBootcamp       float64\n",
       "BootcampFinish         float64\n",
       "BootcampLoanYesNo      float64\n",
       "BootcampName            object\n",
       "                        ...   \n",
       "YouTubeMIT             float64\n",
       "YouTubeMozillaHacks    float64\n",
       "YouTubeOther            object\n",
       "YouTubeSimplilearn     float64\n",
       "YouTubeTheNewBoston    float64\n",
       "Length: 136, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d5cd919-c01c-44bf-92af-2af468aea6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age                     2808\n",
      "AttendedBootcamp         466\n",
      "BootcampFinish         17106\n",
      "BootcampLoanYesNo      17096\n",
      "BootcampName           17226\n",
      "                       ...  \n",
      "YouTubeMIT             14848\n",
      "YouTubeMozillaHacks    17553\n",
      "YouTubeOther           17027\n",
      "YouTubeSimplilearn     17974\n",
      "YouTubeTheNewBoston    15215\n",
      "Length: 136, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values = data_cleaned.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a950b098-eea6-49ed-9858-78fa4a174801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Handle missing values by removing rows with missing values\n",
    "data_cleaned = data_cleaned.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9c12f94-d959-403d-97fe-baf52052d514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Remove duplicate records\n",
    "data_cleaned = data_cleaned.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f45a6054-746b-49bc-ad8a-bfdc15fd7ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Merge Columns\n",
    "# Merge 'Do you financially support any dependents?' and 'Do you have children?' into 'Dependents'\n",
    "def merge_dependents(row):\n",
    "    # Check if both columns exist and apply logic\n",
    "    if 'Do you financially support any dependents?' in row.index and 'Do you have children?' in row.index:\n",
    "        if row['Do you financially support any dependents?'] == 'Yes' or row['Do you have children?'] == 'Yes':\n",
    "            return 'Yes'\n",
    "        else:\n",
    "            return 'No'\n",
    "    return np.nan  # Return NaN if columns do not exist\n",
    "# Apply the function to create the 'Dependents' column\n",
    "data_cleaned['Dependents'] = data_cleaned.apply(merge_dependents, axis=1)\n",
    "# Merge 'Do you have student loan debt?', 'Do you have any debt?', and 'Do you have a home mortgage?' into 'Debt status category'\n",
    "def merge_debt(row):\n",
    "    if 'Do you have student loan debt?' in row.index and row['Do you have student loan debt?'] == 'Yes':\n",
    "        return 'Student Loan'\n",
    "    elif 'Do you have a home mortgage?' in row.index and row['Do you have a home mortgage?'] == 'Yes':\n",
    "        return 'Mortgage'\n",
    "    elif 'Do you have any debt?' in row.index and row['Do you have any debt?'] == 'Yes':\n",
    "        return 'Other Debt'\n",
    "    else:\n",
    "        return 'No Debt'\n",
    "# Apply the function to create the 'Debt status category' column\n",
    "data_cleaned['Debt status category'] = data_cleaned.apply(merge_debt, axis=1)\n",
    "# Merge 'Other' columns ('Other' gender, employment/school, career)\n",
    "def merge_other(row):\n",
    "    if 'Other' in row.index and pd.notna(row['Other']):\n",
    "        return row['Other']\n",
    "    elif 'Other.1' in row.index and pd.notna(row['Other.1']):\n",
    "        return row['Other.1']\n",
    "    elif 'Other.2' in row.index and pd.notna(row['Other.2']):\n",
    "        return row['Other.2']\n",
    "    return np.nan\n",
    "# Apply the function to merge 'Other' columns\n",
    "data_cleaned['Other'] = data_cleaned.apply(merge_other, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fe6e90c-6311-4d3e-aa66-1ff67977e5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Remove irrelevant columns\n",
    "columns_to_remove = ['Submit Date (UTC)', 'Start Date (UTC)', 'Network ID', 'Other.1', 'Other.2', 'Other']\n",
    "data_cleaned = data_cleaned.drop(columns=[col for col in columns_to_remove if col in data_cleaned.columns])\n",
    "# Step 5: Handle any inconsistencies in the data (assuming none for now)\n",
    "# The data is now cleaned and ready for machine learning algorithms.\n",
    "# Optional: Save the cleaned data to a new CSV file\n",
    "data_cleaned.to_csv('cleaned_survey_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9b7cd83-0bc0-464b-94f7-aca9bb269d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Remove irrelevant columns if they exist in the dataset\n",
    "columns_to_remove = ['Submit Date (UTC)', 'Start Date (UTC)', 'Network ID', '#', 'Other', 'Other.1', 'Other.2']\n",
    "# Check if each column exists before dropping\n",
    "data_cleaned = data_cleaned.drop(columns=[col for col in columns_to_remove if col in data_cleaned.columns], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1c6fbaa-536c-44ee-b195-d509c1457c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Age, AttendedBootcamp, BootcampFinish, BootcampLoanYesNo, BootcampName, BootcampRecommend, ChildrenNumber, CityPopulation, CodeEventConferences, CodeEventDjangoGirls, CodeEventFCC, CodeEventGameJam, CodeEventGirlDev, CodeEventHackathons, CodeEventMeetup, CodeEventNodeSchool, CodeEventNone, CodeEventOther, CodeEventRailsBridge, CodeEventRailsGirls, CodeEventStartUpWknd, CodeEventWkdBootcamps, CodeEventWomenCode, CodeEventWorkshops, CommuteTime, CountryCitizen, CountryLive, EmploymentField, EmploymentFieldOther, EmploymentStatus, EmploymentStatusOther, ExpectedEarning, FinanciallySupporting, FirstDevJob, Gender, GenderOther, HasChildren, HasDebt, HasFinancialDependents, HasHighSpdInternet, HasHomeMortgage, HasServedInMilitary, HasStudentDebt, HomeMortgageOwe, HoursLearning, ID.x, ID.y, Income, IsEthnicMinority, IsReceiveDisabilitiesBenefits, IsSoftwareDev, IsUnderEmployed, JobApplyWhen, JobInterestBackEnd, JobInterestDataEngr, JobInterestDataSci, JobInterestDevOps, JobInterestFrontEnd, JobInterestFullStack, JobInterestGameDev, JobInterestInfoSec, JobInterestMobile, JobInterestOther, JobInterestProjMngr, JobInterestQAEngr, JobInterestUX, JobPref, JobRelocateYesNo, JobRoleInterest, JobWherePref, LanguageAtHome, MaritalStatus, MoneyForLearning, MonthsProgramming, NetworkID, Part1EndTime, Part1StartTime, Part2EndTime, Part2StartTime, PodcastChangeLog, PodcastCodeNewbie, PodcastCodePen, PodcastDevTea, PodcastDotNET, PodcastGiantRobots, PodcastJSAir, PodcastJSJabber, PodcastNone, PodcastOther, PodcastProgThrowdown, PodcastRubyRogues, PodcastSEDaily, PodcastSERadio, PodcastShopTalk, PodcastTalkPython, PodcastTheWebAhead, ResourceCodecademy, ResourceCodeWars, ResourceCoursera, ResourceCSS, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 138 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Display cleaned data (or save it to a new CSV file)\n",
    "print(data_cleaned.head())  # Display the first few rows\n",
    "# If you want to save the cleaned data to a new file\n",
    "data_cleaned.to_csv('cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "919dad59-bfc9-46b8-907a-58b91aac805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Label Encoding for small categories and ordinal features\n",
    "label_encoder = LabelEncoder()\n",
    "# Label encode Gender (if binary or small categories)\n",
    "if 'Gender' in data_cleaned.columns:\n",
    "    data_cleaned['Gender_Encoded'] = label_encoder.fit_transform(data_cleaned['Gender'])\n",
    "# Label encode Degree Level (ordinal)\n",
    "if 'Degree Level' in data_cleaned.columns:\n",
    "    data_cleaned['Degree_Level_Encoded'] = label_encoder.fit_transform(data_cleaned['Degree Level'])\n",
    "# Label encode Employment Status\n",
    "if 'Employment Status' in data_cleaned.columns:\n",
    "    data_cleaned['Employment_Status_Encoded'] = label_encoder.fit_transform(data_cleaned['Employment Status'])\n",
    "# Label encode Student Loan Debt (Yes/No or binary)\n",
    "if 'Do you have student loan debt?' in data_cleaned.columns:\n",
    "    data_cleaned['Student_Loan_Debt_Encoded'] = label_encoder.fit_transform(data_cleaned['Do you have student loan debt?'])\n",
    "# Label encode Family Responsibilities (Yes/No for dependents, children)\n",
    "if 'Dependents' in data_cleaned.columns:\n",
    "    data_cleaned['Dependents_Encoded'] = label_encoder.fit_transform(data_cleaned['Dependents'])\n",
    "# Step 2: One-Hot Encoding for unordered categorical variables\n",
    "# One-hot encode Country of Residence\n",
    "if 'Country of Residence' in data_cleaned.columns:\n",
    "    data_cleaned = pd.get_dummies(data_cleaned, columns=['Country of Residence'], prefix='Country')\n",
    "# One-hot encode Citizenship\n",
    "if 'Citizenship' in data_cleaned.columns:\n",
    "    data_cleaned = pd.get_dummies(data_cleaned, columns=['Citizenship'], prefix='Citizenship')\n",
    "# One-hot encode Job Roles\n",
    "if 'Job Roles' in data_cleaned.columns:\n",
    "    data_cleaned = pd.get_dummies(data_cleaned, columns=['Job Roles'], prefix='Job_Role')\n",
    "# One-hot encode Field of Study\n",
    "if 'Field of Study' in data_cleaned.columns:\n",
    "    data_cleaned = pd.get_dummies(data_cleaned, columns=['Field of Study'], prefix='Field_Study')\n",
    "# One-hot encode Learning Preferences\n",
    "if 'Learning Preferences' in data_cleaned.columns:\n",
    "    data_cleaned = pd.get_dummies(data_cleaned, columns=['Learning Preferences'], prefix='Learning_Pref')\n",
    "# One-hot encode Coding Events/Workshops\n",
    "if 'Coding Events/Workshops' in data_cleaned.columns:\n",
    "    data_cleaned = pd.get_dummies(data_cleaned, columns=['Coding Events/Workshops'], prefix='Coding_Event')\n",
    "# One-hot encode Employment Type Preferences\n",
    "if 'Employment Type Preferences' in data_cleaned.columns:\n",
    "    data_cleaned = pd.get_dummies(data_cleaned, columns=['Employment Type Preferences'], prefix='Employment_Type')\n",
    "# Optional: Step 3: Handling High-Cardinality Features\n",
    "# For very high-cardinality categorical features like 'Country', if dimensionality becomes an issue,\n",
    "# consider using binary encoding from the 'category_encoders' library.\n",
    "# Example: Using binary encoding for 'Country' feature with many categories\n",
    "# Install the category_encoders package if needed:\n",
    "# !pip install category_encoders\n",
    "# from category_encoders import BinaryEncoder\n",
    "# encoder = BinaryEncoder(cols=['Country'])\n",
    "# data_cleaned = encoder.fit_transform(data_cleaned)\n",
    "# Save the encoded dataset to a new CSV file\n",
    "data_cleaned.to_csv('encoded_survey_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "74c7a2ca-ffe3-4ad4-96e5-ee8e455ea510",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\philk\\AppData\\Local\\Temp\\ipykernel_70596\\3691866491.py:3: DtypeWarning: Columns (17,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data_cleaned = pd.read_csv('./clean-data/2017-fCC-New-Coders-Survey-Data.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to scale:  ['Age', 'AttendedBootcamp', 'BootcampFinish', 'BootcampLoanYesNo', 'BootcampRecommend', 'ChildrenNumber', 'CodeEventConferences', 'CodeEventDjangoGirls', 'CodeEventFCC', 'CodeEventGameJam', 'CodeEventGirlDev', 'CodeEventHackathons', 'CodeEventMeetup', 'CodeEventNodeSchool', 'CodeEventNone', 'CodeEventRailsBridge', 'CodeEventRailsGirls', 'CodeEventStartUpWknd', 'CodeEventWkdBootcamps', 'CodeEventWomenCode', 'CodeEventWorkshops', 'ExpectedEarning', 'FinanciallySupporting', 'FirstDevJob', 'HasChildren', 'HasDebt', 'HasFinancialDependents', 'HasHighSpdInternet', 'HasHomeMortgage', 'HasServedInMilitary', 'HasStudentDebt', 'HomeMortgageOwe', 'HoursLearning', 'Income', 'IsEthnicMinority', 'IsReceiveDisabilitiesBenefits', 'IsSoftwareDev', 'IsUnderEmployed', 'JobInterestBackEnd', 'JobInterestDataEngr', 'JobInterestDataSci', 'JobInterestDevOps', 'JobInterestFrontEnd', 'JobInterestFullStack', 'JobInterestGameDev', 'JobInterestInfoSec', 'JobInterestMobile', 'JobInterestProjMngr', 'JobInterestQAEngr', 'JobInterestUX', 'JobRelocateYesNo', 'MoneyForLearning', 'MonthsProgramming', 'PodcastChangeLog', 'PodcastCodeNewbie', 'PodcastCodePen', 'PodcastDevTea', 'PodcastDotNET', 'PodcastGiantRobots', 'PodcastJSAir', 'PodcastJSJabber', 'PodcastNone', 'PodcastProgThrowdown', 'PodcastRubyRogues', 'PodcastSEDaily', 'PodcastSERadio', 'PodcastShopTalk', 'PodcastTalkPython', 'PodcastTheWebAhead', 'ResourceCodecademy', 'ResourceCodeWars', 'ResourceCoursera', 'ResourceCSS', 'ResourceEdX', 'ResourceEgghead', 'ResourceFCC', 'ResourceHackerRank', 'ResourceKA', 'ResourceLynda', 'ResourceMDN', 'ResourceOdinProj', 'ResourcePluralSight', 'ResourceSkillcrush', 'ResourceSO', 'ResourceTreehouse', 'ResourceUdacity', 'ResourceUdemy', 'ResourceW3S', 'StudentDebtOwe', 'YouTubeCodeCourse', 'YouTubeCodingTrain', 'YouTubeCodingTut360', 'YouTubeComputerphile', 'YouTubeDerekBanas', 'YouTubeDevTips', 'YouTubeEngineeredTruth', 'YouTubeFCC', 'YouTubeFunFunFunction', 'YouTubeGoogleDev', 'YouTubeLearnCode', 'YouTubeLevelUpTuts', 'YouTubeMIT', 'YouTubeMozillaHacks', 'YouTubeSimplilearn', 'YouTubeTheNewBoston']\n",
      "        Age  AttendedBootcamp  BootcampFinish  BootcampLoanYesNo BootcampName  \\\n",
      "0  0.300000               0.0             NaN                NaN          NaN   \n",
      "1  0.377778               0.0             NaN                NaN          NaN   \n",
      "2  0.233333               0.0             NaN                NaN          NaN   \n",
      "3  0.288889               0.0             NaN                NaN          NaN   \n",
      "4  0.222222               0.0             NaN                NaN          NaN   \n",
      "\n",
      "   BootcampRecommend  ChildrenNumber                 CityPopulation  \\\n",
      "0                NaN             NaN            more than 1 million   \n",
      "1                NaN             NaN              less than 100,000   \n",
      "2                NaN             NaN            more than 1 million   \n",
      "3                NaN             NaN  between 100,000 and 1 million   \n",
      "4                NaN             NaN  between 100,000 and 1 million   \n",
      "\n",
      "   CodeEventConferences  CodeEventDjangoGirls  ...  YouTubeFCC  \\\n",
      "0                   NaN                   NaN  ...         NaN   \n",
      "1                   NaN                   NaN  ...         0.0   \n",
      "2                   NaN                   NaN  ...         NaN   \n",
      "3                   NaN                   NaN  ...         0.0   \n",
      "4                   NaN                   NaN  ...         NaN   \n",
      "\n",
      "   YouTubeFunFunFunction  YouTubeGoogleDev  YouTubeLearnCode  \\\n",
      "0                    NaN               NaN               NaN   \n",
      "1                    NaN               NaN               NaN   \n",
      "2                    NaN               NaN               0.0   \n",
      "3                    0.0               NaN               NaN   \n",
      "4                    NaN               NaN               NaN   \n",
      "\n",
      "   YouTubeLevelUpTuts  YouTubeMIT  YouTubeMozillaHacks YouTubeOther  \\\n",
      "0                 NaN         NaN                  NaN          NaN   \n",
      "1                 NaN         NaN                  NaN          NaN   \n",
      "2                 0.0         NaN                  NaN          NaN   \n",
      "3                 0.0         NaN                  NaN          NaN   \n",
      "4                 NaN         NaN                  NaN          NaN   \n",
      "\n",
      "   YouTubeSimplilearn  YouTubeTheNewBoston  \n",
      "0                 NaN                  NaN  \n",
      "1                 NaN                  NaN  \n",
      "2                 NaN                  NaN  \n",
      "3                 NaN                  NaN  \n",
      "4                 NaN                  NaN  \n",
      "\n",
      "[5 rows x 136 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# Load the dataset (replace with your actual file path)\n",
    "data_cleaned = pd.read_csv('./clean-data/2017-fCC-New-Coders-Survey-Data.csv')\n",
    "# Step 1: Identify Numerical Columns\n",
    "# Select only numerical columns (int64 and float64)\n",
    "numerical_columns = data_cleaned.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "# Step 2: Exclude binary or categorical columns from scaling\n",
    "# Define the binary or categorical columns that should not be scaled\n",
    "exclude_columns = ['Dependents', 'Gender', 'Employment Status']  # Add any other binary or categorical columns here\n",
    "# Identify the numerical columns to scale by excluding the binary/categorical columns\n",
    "columns_to_scale = [col for col in numerical_columns if col not in exclude_columns]\n",
    "print(\"Columns to scale: \", columns_to_scale)\n",
    "# Step 3: Normalize the selected columns using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "data_cleaned[columns_to_scale] = scaler.fit_transform(data_cleaned[columns_to_scale])\n",
    "# Step 4: Standardize the selected columns using StandardScaler (if you want to standardize instead of normalize)\n",
    "# scaler = StandardScaler()\n",
    "# data_cleaned[columns_to_scale] = scaler.fit_transform(data_cleaned[columns_to_scale])\n",
    "# The data is now normalized (or standardized if you uncomment the StandardScaler)\n",
    "# Optional: Save the final processed data\n",
    "data_cleaned.to_csv('final_processed_data.csv', index=False)\n",
    "# Check the first few rows of the scaled data\n",
    "print(data_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9400d70c-9c85-40dc-b8e7-c4e73d78fd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466\n",
      "17106\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in 'AttendedBootcamp' and 'BootcampFinish'\n",
    "print(data_cleaned['AttendedBootcamp'].isnull().sum())\n",
    "print(data_cleaned['BootcampFinish'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4016fe0c-184c-461a-891d-d45c882f6e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where 'AttendedBootcamp' or 'BootcampFinish' have NaN values\n",
    "data_cleaned = data_cleaned.dropna(subset=['AttendedBootcamp', 'BootcampFinish'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c63ea0b2-6392-439e-aafe-55c863c230d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and targets ('AttendedBootcamp' and 'BootcampFinish') again after removing NaNs\n",
    "X = data_cleaned.drop(columns=['AttendedBootcamp', 'BootcampFinish'])  # Features\n",
    "y_attend = data_cleaned['AttendedBootcamp']  # Target 1: Attend Bootcamp\n",
    "y_finish = data_cleaned['BootcampFinish']  # Target 2: Finish Bootcamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d477b819-0fff-4e96-800f-fddadee0714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split data for 'AttendedBootcamp' prediction with stratified sampling\n",
    "X_train_attend, X_test_attend, y_train_attend, y_test_attend = train_test_split(X, y_attend, test_size=0.3, stratify=y_attend, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b7fbf5f0-3841-4522-ad07-6e97e284ccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for 'BootcampFinish' prediction with stratified sampling\n",
    "X_train_finish, X_test_finish, y_train_finish, y_test_finish = train_test_split(X, y_finish, test_size=0.3, stratify=y_finish, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f3e0cbcf-d7a5-4ed1-ba98-0ba5ac1f430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths for each member (you can modify these paths as needed)\n",
    "path_ayana = \"datasets/ayana/\"\n",
    "path_roberta = \"datasets/roberta/\"\n",
    "path_dom = \"datasets/dom/\"\n",
    "path_phillip = \"datasets/phillip/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7968f8b9-7d2b-4209-93b3-466be824f3c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create directories if they don't exist\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(path_ayana, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(path_roberta, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(path_dom, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# Create directories if they don't exist\n",
    "os.makedirs(path_ayana, exist_ok=True)\n",
    "os.makedirs(path_roberta, exist_ok=True)\n",
    "os.makedirs(path_dom, exist_ok=True)\n",
    "os.makedirs(path_phillip, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "be798ed2-4fa7-4341-862f-1ec0d610459b",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'datasets\\ayana'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ensure the paths exist (if necessary)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# For Ayana: Logistic Regression & Decision Trees (AttendedBootcamp and BootcampFinish)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Export Ayana's training and test datasets for AttendedBootcamp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m X_train_attend\u001b[38;5;241m.\u001b[39mto_csv(path_ayana \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_train_attend.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m y_train_attend\u001b[38;5;241m.\u001b[39mto_csv(path_ayana \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_train_attend.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m X_test_attend\u001b[38;5;241m.\u001b[39mto_csv(path_ayana \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_test_attend.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3965\u001b[0m )\n\u001b[1;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[0;32m   3968\u001b[0m     path_or_buf,\n\u001b[0;32m   3969\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   3970\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[0;32m   3971\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   3972\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   3973\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   3974\u001b[0m     quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[0;32m   3975\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   3976\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m   3977\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   3978\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m   3979\u001b[0m     quotechar\u001b[38;5;241m=\u001b[39mquotechar,\n\u001b[0;32m   3980\u001b[0m     date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[0;32m   3981\u001b[0m     doublequote\u001b[38;5;241m=\u001b[39mdoublequote,\n\u001b[0;32m   3982\u001b[0m     escapechar\u001b[38;5;241m=\u001b[39mescapechar,\n\u001b[0;32m   3983\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   3984\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m csv_formatter\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    254\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    255\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,\n\u001b[0;32m    256\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression,\n\u001b[0;32m    257\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options,\n\u001b[0;32m    258\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[1;32m--> 749\u001b[0m     check_parent_directory(\u001b[38;5;28mstr\u001b[39m(handle))\n\u001b[0;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'datasets\\ayana'"
     ]
    }
   ],
   "source": [
    "# Ensure the paths exist (if necessary)\n",
    "# For Ayana: Logistic Regression & Decision Trees (AttendedBootcamp and BootcampFinish)\n",
    "# Export Ayana's training and test datasets for AttendedBootcamp\n",
    "X_train_attend.to_csv(path_ayana + \"X_train_attend.csv\", index=False)\n",
    "y_train_attend.to_csv(path_ayana + \"y_train_attend.csv\", index=False)\n",
    "X_test_attend.to_csv(path_ayana + \"X_test_attend.csv\", index=False)\n",
    "y_test_attend.to_csv(path_ayana + \"y_test_attend.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608b26e0-ce41-448e-8a33-caeeb36d8020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Ayana's training and test datasets for BootcampFinish\n",
    "X_train_finish.to_csv(path_ayana + \"X_train_finish.csv\", index=False)\n",
    "y_train_finish.to_csv(path_ayana + \"y_train_finish.csv\", index=False)\n",
    "X_test_finish.to_csv(path_ayana + \"X_test_finish.csv\", index=False)\n",
    "y_test_finish.to_csv(path_ayana + \"y_test_finish.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5110d24-9a6e-4926-a571-eb54a1635556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787dc1c4-4baa-4f5b-bd69-482cbf013658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Roberta: Random Forest\n",
    "X_train_attend.to_csv(path_roberta + \"X_train_attend.csv\", index=False)\n",
    "y_train_attend.to_csv(path_roberta + \"y_train_attend.csv\", index=False)\n",
    "X_test_attend.to_csv(path_roberta + \"X_test_attend.csv\", index=False)\n",
    "y_test_attend.to_csv(path_roberta + \"y_test_attend.csv\", index=False)\n",
    "X_train_finish.to_csv(path_roberta + \"X_train_finish.csv\", index=False)\n",
    "y_train_finish.to_csv(path_roberta + \"y_train_finish.csv\", index=False)\n",
    "X_test_finish.to_csv(path_roberta + \"X_test_finish.csv\", index=False)\n",
    "y_test_finish.to_csv(path_roberta + \"y_test_finish.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3828d24-e230-4442-ad53-22128c244e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Dom: SVM & KNN\n",
    "X_train_attend.to_csv(path_dom + \"X_train_attend.csv\", index=False)\n",
    "y_train_attend.to_csv(path_dom + \"y_train_attend.csv\", index=False)\n",
    "X_test_attend.to_csv(path_dom + \"X_test_attend.csv\", index=False)\n",
    "y_test_attend.to_csv(path_dom + \"y_test_attend.csv\", index=False)\n",
    "X_train_finish.to_csv(path_dom + \"X_train_finish.csv\", index=False)\n",
    "y_train_finish.to_csv(path_dom + \"y_train_finish.csv\", index=False)\n",
    "X_test_finish.to_csv(path_dom + \"X_test_finish.csv\", index=False)\n",
    "y_test_finish.to_csv(path_dom + \"y_test_finish.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20933319-45de-432f-9152-e34a56406d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Phillip: XGBoost & LightGBM\n",
    "X_train_attend.to_csv(path_phillip + \"X_train_attend.csv\", index=False)\n",
    "y_train_attend.to_csv(path_phillip + \"y_train_attend.csv\", index=False)\n",
    "X_test_attend.to_csv(path_phillip + \"X_test_attend.csv\", index=False)\n",
    "y_test_attend.to_csv(path_phillip + \"y_test_attend.csv\", index=False)\n",
    "X_train_finish.to_csv(path_phillip + \"X_train_finish.csv\", index=False)\n",
    "y_train_finish.to_csv(path_phillip + \"y_train_finish.csv\", index=False)\n",
    "X_test_finish.to_csv(path_phillip + \"X_test_finish.csv\", index=False)\n",
    "y_test_finish.to_csv(path_phillip + \"y_test_finish.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3fc327-6f64-4618-af60-38191ebaa9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can export the clean dataset for each member as well\n",
    "data_cleaned.to_csv(path_ayana + \"clean_dataset.csv\", index=False)\n",
    "data_cleaned.to_csv(path_roberta + \"clean_dataset.csv\", index=False)\n",
    "data_cleaned.to_csv(path_dom + \"clean_dataset.csv\", index=False)\n",
    "data_cleaned.to_csv(path_phillip + \"clean_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d97b75-f364-40c8-9694-bad7f83a3bcb",
   "metadata": {},
   "source": [
    "# Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7826921-83cd-4213-8fae-c72acbaaf0f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Find the percentage of null values in each column\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_train\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(X_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Find the percentage of null values in each column\n",
    "X_train.isna().sum()/len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0757d3b6-377c-4f5d-9e2d-9592a6d8bd29",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Explore each column with missing values to determine the best fill strategy\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# First the job column\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m X_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<Choose Column>\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Explore each column with missing values to determine the best fill strategy\n",
    "# First the job column\n",
    "X_train['<Choose Column>'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47db665-338d-4599-a7f9-01459a566fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
