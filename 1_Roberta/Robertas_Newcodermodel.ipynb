{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "964c9180-6e36-4e2b-bf3e-46f2ee4dd86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberta Chandler\\AppData\\Local\\Temp\\ipykernel_33952\\3040135482.py:11: DtypeWarning: Columns (17,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data_cleaned = pd.read_csv(file_path)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>AttendedBootcamp</th>\n",
       "      <th>BootcampFinish</th>\n",
       "      <th>BootcampLoanYesNo</th>\n",
       "      <th>BootcampName</th>\n",
       "      <th>BootcampRecommend</th>\n",
       "      <th>ChildrenNumber</th>\n",
       "      <th>CityPopulation</th>\n",
       "      <th>CodeEventConferences</th>\n",
       "      <th>CodeEventDjangoGirls</th>\n",
       "      <th>...</th>\n",
       "      <th>YouTubeFCC</th>\n",
       "      <th>YouTubeFunFunFunction</th>\n",
       "      <th>YouTubeGoogleDev</th>\n",
       "      <th>YouTubeLearnCode</th>\n",
       "      <th>YouTubeLevelUpTuts</th>\n",
       "      <th>YouTubeMIT</th>\n",
       "      <th>YouTubeMozillaHacks</th>\n",
       "      <th>YouTubeOther</th>\n",
       "      <th>YouTubeSimplilearn</th>\n",
       "      <th>YouTubeTheNewBoston</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>more than 1 million</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>less than 100,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>more than 1 million</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>between 100,000 and 1 million</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>between 100,000 and 1 million</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  AttendedBootcamp  BootcampFinish  BootcampLoanYesNo BootcampName  \\\n",
       "0  27.0               0.0             NaN                NaN          NaN   \n",
       "1  34.0               0.0             NaN                NaN          NaN   \n",
       "2  21.0               0.0             NaN                NaN          NaN   \n",
       "3  26.0               0.0             NaN                NaN          NaN   \n",
       "4  20.0               0.0             NaN                NaN          NaN   \n",
       "\n",
       "   BootcampRecommend  ChildrenNumber                 CityPopulation  \\\n",
       "0                NaN             NaN            more than 1 million   \n",
       "1                NaN             NaN              less than 100,000   \n",
       "2                NaN             NaN            more than 1 million   \n",
       "3                NaN             NaN  between 100,000 and 1 million   \n",
       "4                NaN             NaN  between 100,000 and 1 million   \n",
       "\n",
       "   CodeEventConferences  CodeEventDjangoGirls  ...  YouTubeFCC  \\\n",
       "0                   NaN                   NaN  ...         NaN   \n",
       "1                   NaN                   NaN  ...         1.0   \n",
       "2                   NaN                   NaN  ...         NaN   \n",
       "3                   NaN                   NaN  ...         1.0   \n",
       "4                   NaN                   NaN  ...         NaN   \n",
       "\n",
       "   YouTubeFunFunFunction  YouTubeGoogleDev  YouTubeLearnCode  \\\n",
       "0                    NaN               NaN               NaN   \n",
       "1                    NaN               NaN               NaN   \n",
       "2                    NaN               NaN               1.0   \n",
       "3                    1.0               NaN               NaN   \n",
       "4                    NaN               NaN               NaN   \n",
       "\n",
       "   YouTubeLevelUpTuts  YouTubeMIT  YouTubeMozillaHacks YouTubeOther  \\\n",
       "0                 NaN         NaN                  NaN          NaN   \n",
       "1                 NaN         NaN                  NaN          NaN   \n",
       "2                 1.0         NaN                  NaN          NaN   \n",
       "3                 1.0         NaN                  NaN          NaN   \n",
       "4                 NaN         NaN                  NaN          NaN   \n",
       "\n",
       "   YouTubeSimplilearn  YouTubeTheNewBoston  \n",
       "0                 NaN                  NaN  \n",
       "1                 NaN                  NaN  \n",
       "2                 NaN                  NaN  \n",
       "3                 NaN                  NaN  \n",
       "4                 NaN                  NaN  \n",
       "\n",
       "[5 rows x 136 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from pathlib import Path\n",
    "file_path = Path(\"Resources/2017-fCC-New-Coders-Survey-Data.csv\")\n",
    "\n",
    "data_cleaned = pd.read_csv(file_path)\n",
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b81d378d-d32b-489f-8c58-9bb2d0277bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18175 entries, 0 to 18174\n",
      "Columns: 136 entries, Age to YouTubeTheNewBoston\n",
      "dtypes: float64(105), object(31)\n",
      "memory usage: 18.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'AttendedBootcamp', 'BootcampFinish', 'BootcampLoanYesNo',\n",
       "       'BootcampName', 'BootcampRecommend', 'ChildrenNumber', 'CityPopulation',\n",
       "       'CodeEventConferences', 'CodeEventDjangoGirls',\n",
       "       ...\n",
       "       'YouTubeFCC', 'YouTubeFunFunFunction', 'YouTubeGoogleDev',\n",
       "       'YouTubeLearnCode', 'YouTubeLevelUpTuts', 'YouTubeMIT',\n",
       "       'YouTubeMozillaHacks', 'YouTubeOther', 'YouTubeSimplilearn',\n",
       "       'YouTubeTheNewBoston'],\n",
       "      dtype='object', length=136)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned.info()\n",
    "data_cleaned.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4abfb61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop=['YouTubeFCC', 'YouTubeFunFunFunction', 'YouTubeGoogleDev', 'YouTubeLearnCode', 'YouTubeLevelUpTuts', 'YouTubeMIT', 'YouTubeMozillaHacks', 'YouTubeOther', 'YouTubeSimplilearn', 'YouTubeTheNewBoston', 'YouTubeDerekBanas', 'YouTubeDevTips', 'YouTubeEngineeredTruth']\n",
    "data_cleaned.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "data_cleaned.columns\n",
    "\n",
    "data_cleaned.to_csv(\"Newdf.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6a92d086-483f-4007-a36c-8341423c77f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                     float64\n",
       "AttendedBootcamp        float64\n",
       "BootcampFinish          float64\n",
       "BootcampLoanYesNo       float64\n",
       "BootcampName             object\n",
       "                         ...   \n",
       "StudentDebtOwe          float64\n",
       "YouTubeCodeCourse       float64\n",
       "YouTubeCodingTrain      float64\n",
       "YouTubeCodingTut360     float64\n",
       "YouTubeComputerphile    float64\n",
       "Length: 123, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6d5cd919-c01c-44bf-92af-2af468aea6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age                      2808\n",
      "AttendedBootcamp          466\n",
      "BootcampFinish          17106\n",
      "BootcampLoanYesNo       17096\n",
      "BootcampName            17226\n",
      "                        ...  \n",
      "StudentDebtOwe          14813\n",
      "YouTubeCodeCourse       17219\n",
      "YouTubeCodingTrain      17199\n",
      "YouTubeCodingTut360     16778\n",
      "YouTubeComputerphile    16722\n",
      "Length: 123, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values = data_cleaned.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a950b098-eea6-49ed-9858-78fa4a174801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Handle missing values by removing rows with missing values\n",
    "data_cleaned = data_cleaned.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e9c12f94-d959-403d-97fe-baf52052d514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Remove duplicate records\n",
    "data_cleaned = data_cleaned.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f45a6054-746b-49bc-ad8a-bfdc15fd7ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Merge Columns\n",
    "# Merge 'Do you financially support any dependents?' and 'Do you have children?' into 'Dependents'\n",
    "def merge_dependents(row):\n",
    "    # Check if both columns exist and apply logic\n",
    "    if 'Do you financially support any dependents?' in row.index and 'Do you have children?' in row.index:\n",
    "        if row['Do you financially support any dependents?'] == 'Yes' or row['Do you have children?'] == 'Yes':\n",
    "            return 'Yes'\n",
    "        else:\n",
    "            return 'No'\n",
    "    return np.nan  # Return NaN if columns do not exist\n",
    "# Apply the function to create the 'Dependents' column\n",
    "data_cleaned['Dependents'] = data_cleaned.apply(merge_dependents, axis=1)\n",
    "# Merge 'Do you have student loan debt?', 'Do you have any debt?', and 'Do you have a home mortgage?' into 'Debt status category'\n",
    "def merge_debt(row):\n",
    "    if 'Do you have student loan debt?' in row.index and row['Do you have student loan debt?'] == 'Yes':\n",
    "        return 'Student Loan'\n",
    "    elif 'Do you have a home mortgage?' in row.index and row['Do you have a home mortgage?'] == 'Yes':\n",
    "        return 'Mortgage'\n",
    "    elif 'Do you have any debt?' in row.index and row['Do you have any debt?'] == 'Yes':\n",
    "        return 'Other Debt'\n",
    "    else:\n",
    "        return 'No Debt'\n",
    "# Apply the function to create the 'Debt status category' column\n",
    "data_cleaned['Debt status category'] = data_cleaned.apply(merge_debt, axis=1)\n",
    "# Merge 'Other' columns ('Other' gender, employment/school, career)\n",
    "def merge_other(row):\n",
    "    if 'Other' in row.index and pd.notna(row['Other']):\n",
    "        return row['Other']\n",
    "    elif 'Other.1' in row.index and pd.notna(row['Other.1']):\n",
    "        return row['Other.1']\n",
    "    elif 'Other.2' in row.index and pd.notna(row['Other.2']):\n",
    "        return row['Other.2']\n",
    "    return np.nan\n",
    "# Apply the function to merge 'Other' columns\n",
    "data_cleaned['Other'] = data_cleaned.apply(merge_other, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9fe6e90c-6311-4d3e-aa66-1ff67977e5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Remove irrelevant columns\n",
    "columns_to_remove = ['Submit Date (UTC)', 'Start Date (UTC)', 'Network ID', 'Other.1', 'Other.2', 'Other']\n",
    "data_cleaned = data_cleaned.drop(columns=[col for col in columns_to_remove if col in data_cleaned.columns])\n",
    "# Step 5: Handle any inconsistencies in the data (assuming none for now)\n",
    "# The data is now cleaned and ready for machine learning algorithms.\n",
    "# Optional: Save the cleaned data to a new CSV file\n",
    "data_cleaned.to_csv('cleaned_survey_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b9b7cd83-0bc0-464b-94f7-aca9bb269d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Remove irrelevant columns if they exist in the dataset\n",
    "columns_to_remove = ['Submit Date (UTC)', 'Start Date (UTC)', 'Network ID', '#', 'Other', 'Other.1', 'Other.2']\n",
    "# Check if each column exists before dropping\n",
    "data_cleaned = data_cleaned.drop(columns=[col for col in columns_to_remove if col in data_cleaned.columns], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f1c6fbaa-536c-44ee-b195-d509c1457c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Age, AttendedBootcamp, BootcampFinish, BootcampLoanYesNo, BootcampName, BootcampRecommend, ChildrenNumber, CityPopulation, CodeEventConferences, CodeEventDjangoGirls, CodeEventFCC, CodeEventGameJam, CodeEventGirlDev, CodeEventHackathons, CodeEventMeetup, CodeEventNodeSchool, CodeEventNone, CodeEventOther, CodeEventRailsBridge, CodeEventRailsGirls, CodeEventStartUpWknd, CodeEventWkdBootcamps, CodeEventWomenCode, CodeEventWorkshops, CommuteTime, CountryCitizen, CountryLive, EmploymentField, EmploymentFieldOther, EmploymentStatus, EmploymentStatusOther, ExpectedEarning, FinanciallySupporting, FirstDevJob, Gender, GenderOther, HasChildren, HasDebt, HasFinancialDependents, HasHighSpdInternet, HasHomeMortgage, HasServedInMilitary, HasStudentDebt, HomeMortgageOwe, HoursLearning, ID.x, ID.y, Income, IsEthnicMinority, IsReceiveDisabilitiesBenefits, IsSoftwareDev, IsUnderEmployed, JobApplyWhen, JobInterestBackEnd, JobInterestDataEngr, JobInterestDataSci, JobInterestDevOps, JobInterestFrontEnd, JobInterestFullStack, JobInterestGameDev, JobInterestInfoSec, JobInterestMobile, JobInterestOther, JobInterestProjMngr, JobInterestQAEngr, JobInterestUX, JobPref, JobRelocateYesNo, JobRoleInterest, JobWherePref, LanguageAtHome, MaritalStatus, MoneyForLearning, MonthsProgramming, NetworkID, Part1EndTime, Part1StartTime, Part2EndTime, Part2StartTime, PodcastChangeLog, PodcastCodeNewbie, PodcastCodePen, PodcastDevTea, PodcastDotNET, PodcastGiantRobots, PodcastJSAir, PodcastJSJabber, PodcastNone, PodcastOther, PodcastProgThrowdown, PodcastRubyRogues, PodcastSEDaily, PodcastSERadio, PodcastShopTalk, PodcastTalkPython, PodcastTheWebAhead, ResourceCodecademy, ResourceCodeWars, ResourceCoursera, ResourceCSS, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 125 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Display cleaned data (or save it to a new CSV file)\n",
    "print(data_cleaned.head())  # Display the first few rows\n",
    "# If you want to save the cleaned data to a new file\n",
    "data_cleaned.to_csv('cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "919dad59-bfc9-46b8-907a-58b91aac805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Label Encoding for small categories and ordinal features\n",
    "label_encoder = LabelEncoder()\n",
    "# Label encode Gender (if binary or small categories)\n",
    "if 'Gender' in data_cleaned.columns:\n",
    "    data_cleaned['Gender_Encoded'] = label_encoder.fit_transform(data_cleaned['Gender'])\n",
    "# Label encode Degree Level (ordinal)\n",
    "if 'Degree Level' in data_cleaned.columns:\n",
    "    data_cleaned['Degree_Level_Encoded'] = label_encoder.fit_transform(data_cleaned['Degree Level'])\n",
    "# Label encode Employment Status\n",
    "if 'Employment Status' in data_cleaned.columns:\n",
    "    data_cleaned['Employment_Status_Encoded'] = label_encoder.fit_transform(data_cleaned['Employment Status'])\n",
    "# Label encode Student Loan Debt (Yes/No or binary)\n",
    "if 'Do you have student loan debt?' in data_cleaned.columns:\n",
    "    data_cleaned['Student_Loan_Debt_Encoded'] = label_encoder.fit_transform(data_cleaned['Do you have student loan debt?'])\n",
    "# Label encode Family Responsibilities (Yes/No for dependents, children)\n",
    "if 'Dependents' in data_cleaned.columns:\n",
    "    data_cleaned['Dependents_Encoded'] = label_encoder.fit_transform(data_cleaned['Dependents'])\n",
    "# Step 2: One-Hot Encoding for unordered categorical variables\n",
    "# One-hot encode Country of Residence\n",
    "if 'Country of Residence' in data_cleaned.columns:\n",
    "    data_cleaned = pd.get_dummies(data_cleaned, columns=['Country of Residence'], prefix='Country')\n",
    "# One-hot encode Citizenship\n",
    "if 'Citizenship' in data_cleaned.columns:\n",
    "    data_cleaned = pd.get_dummies(data_cleaned, columns=['Citizenship'], prefix='Citizenship')\n",
    "# One-hot encode Job Roles\n",
    "if 'Job Roles' in data_cleaned.columns:\n",
    "    data_cleaned = pd.get_dummies(data_cleaned, columns=['Job Roles'], prefix='Job_Role')\n",
    "# One-hot encode Field of Study\n",
    "if 'Field of Study' in data_cleaned.columns:\n",
    "    data_cleaned = pd.get_dummies(data_cleaned, columns=['Field of Study'], prefix='Field_Study')\n",
    "# One-hot encode Learning Preferences\n",
    "if 'Learning Preferences' in data_cleaned.columns:\n",
    "    data_cleaned = pd.get_dummies(data_cleaned, columns=['Learning Preferences'], prefix='Learning_Pref')\n",
    "# One-hot encode Coding Events/Workshops\n",
    "if 'Coding Events/Workshops' in data_cleaned.columns:\n",
    "    data_cleaned = pd.get_dummies(data_cleaned, columns=['Coding Events/Workshops'], prefix='Coding_Event')\n",
    "# One-hot encode Employment Type Preferences\n",
    "if 'Employment Type Preferences' in data_cleaned.columns:\n",
    "    data_cleaned = pd.get_dummies(data_cleaned, columns=['Employment Type Preferences'], prefix='Employment_Type')\n",
    "# Optional: Step 3: Handling High-Cardinality Features\n",
    "# For very high-cardinality categorical features like 'Country', if dimensionality becomes an issue,\n",
    "# consider using binary encoding from the 'category_encoders' library.\n",
    "# Example: Using binary encoding for 'Country' feature with many categories\n",
    "# Install the category_encoders package if needed:\n",
    "# !pip install category_encoders\n",
    "# from category_encoders import BinaryEncoder\n",
    "# encoder = BinaryEncoder(cols=['Country'])\n",
    "# data_cleaned = encoder.fit_transform(data_cleaned)\n",
    "# Save the encoded dataset to a new CSV file\n",
    "data_cleaned.to_csv('encoded_survey_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "74c7a2ca-ffe3-4ad4-96e5-ee8e455ea510",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberta Chandler\\AppData\\Local\\Temp\\ipykernel_33952\\4159019413.py:3: DtypeWarning: Columns (17,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data_cleaned = pd.read_csv('../clean-data/2017-fCC-New-Coders-Survey-Data.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to scale:  ['Age', 'AttendedBootcamp', 'BootcampFinish', 'BootcampLoanYesNo', 'BootcampRecommend', 'ChildrenNumber', 'CodeEventConferences', 'CodeEventDjangoGirls', 'CodeEventFCC', 'CodeEventGameJam', 'CodeEventGirlDev', 'CodeEventHackathons', 'CodeEventMeetup', 'CodeEventNodeSchool', 'CodeEventNone', 'CodeEventRailsBridge', 'CodeEventRailsGirls', 'CodeEventStartUpWknd', 'CodeEventWkdBootcamps', 'CodeEventWomenCode', 'CodeEventWorkshops', 'ExpectedEarning', 'FinanciallySupporting', 'FirstDevJob', 'HasChildren', 'HasDebt', 'HasFinancialDependents', 'HasHighSpdInternet', 'HasHomeMortgage', 'HasServedInMilitary', 'HasStudentDebt', 'HomeMortgageOwe', 'HoursLearning', 'Income', 'IsEthnicMinority', 'IsReceiveDisabilitiesBenefits', 'IsSoftwareDev', 'IsUnderEmployed', 'JobInterestBackEnd', 'JobInterestDataEngr', 'JobInterestDataSci', 'JobInterestDevOps', 'JobInterestFrontEnd', 'JobInterestFullStack', 'JobInterestGameDev', 'JobInterestInfoSec', 'JobInterestMobile', 'JobInterestProjMngr', 'JobInterestQAEngr', 'JobInterestUX', 'JobRelocateYesNo', 'MoneyForLearning', 'MonthsProgramming', 'PodcastChangeLog', 'PodcastCodeNewbie', 'PodcastCodePen', 'PodcastDevTea', 'PodcastDotNET', 'PodcastGiantRobots', 'PodcastJSAir', 'PodcastJSJabber', 'PodcastNone', 'PodcastProgThrowdown', 'PodcastRubyRogues', 'PodcastSEDaily', 'PodcastSERadio', 'PodcastShopTalk', 'PodcastTalkPython', 'PodcastTheWebAhead', 'ResourceCodecademy', 'ResourceCodeWars', 'ResourceCoursera', 'ResourceCSS', 'ResourceEdX', 'ResourceEgghead', 'ResourceFCC', 'ResourceHackerRank', 'ResourceKA', 'ResourceLynda', 'ResourceMDN', 'ResourceOdinProj', 'ResourcePluralSight', 'ResourceSkillcrush', 'ResourceSO', 'ResourceTreehouse', 'ResourceUdacity', 'ResourceUdemy', 'ResourceW3S', 'StudentDebtOwe', 'YouTubeCodeCourse', 'YouTubeCodingTrain', 'YouTubeCodingTut360', 'YouTubeComputerphile', 'YouTubeDerekBanas', 'YouTubeDevTips', 'YouTubeEngineeredTruth', 'YouTubeFCC', 'YouTubeFunFunFunction', 'YouTubeGoogleDev', 'YouTubeLearnCode', 'YouTubeLevelUpTuts', 'YouTubeMIT', 'YouTubeMozillaHacks', 'YouTubeSimplilearn', 'YouTubeTheNewBoston']\n",
      "        Age  AttendedBootcamp  BootcampFinish  BootcampLoanYesNo BootcampName  \\\n",
      "0  0.300000               0.0             NaN                NaN          NaN   \n",
      "1  0.377778               0.0             NaN                NaN          NaN   \n",
      "2  0.233333               0.0             NaN                NaN          NaN   \n",
      "3  0.288889               0.0             NaN                NaN          NaN   \n",
      "4  0.222222               0.0             NaN                NaN          NaN   \n",
      "\n",
      "   BootcampRecommend  ChildrenNumber                 CityPopulation  \\\n",
      "0                NaN             NaN            more than 1 million   \n",
      "1                NaN             NaN              less than 100,000   \n",
      "2                NaN             NaN            more than 1 million   \n",
      "3                NaN             NaN  between 100,000 and 1 million   \n",
      "4                NaN             NaN  between 100,000 and 1 million   \n",
      "\n",
      "   CodeEventConferences  CodeEventDjangoGirls  ...  YouTubeFCC  \\\n",
      "0                   NaN                   NaN  ...         NaN   \n",
      "1                   NaN                   NaN  ...         0.0   \n",
      "2                   NaN                   NaN  ...         NaN   \n",
      "3                   NaN                   NaN  ...         0.0   \n",
      "4                   NaN                   NaN  ...         NaN   \n",
      "\n",
      "   YouTubeFunFunFunction  YouTubeGoogleDev  YouTubeLearnCode  \\\n",
      "0                    NaN               NaN               NaN   \n",
      "1                    NaN               NaN               NaN   \n",
      "2                    NaN               NaN               0.0   \n",
      "3                    0.0               NaN               NaN   \n",
      "4                    NaN               NaN               NaN   \n",
      "\n",
      "   YouTubeLevelUpTuts  YouTubeMIT  YouTubeMozillaHacks YouTubeOther  \\\n",
      "0                 NaN         NaN                  NaN          NaN   \n",
      "1                 NaN         NaN                  NaN          NaN   \n",
      "2                 0.0         NaN                  NaN          NaN   \n",
      "3                 0.0         NaN                  NaN          NaN   \n",
      "4                 NaN         NaN                  NaN          NaN   \n",
      "\n",
      "   YouTubeSimplilearn  YouTubeTheNewBoston  \n",
      "0                 NaN                  NaN  \n",
      "1                 NaN                  NaN  \n",
      "2                 NaN                  NaN  \n",
      "3                 NaN                  NaN  \n",
      "4                 NaN                  NaN  \n",
      "\n",
      "[5 rows x 136 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# Load the dataset (replace with your actual file path)\n",
    "data_cleaned = pd.read_csv('../clean-data/2017-fCC-New-Coders-Survey-Data.csv')\n",
    "# Step 1: Identify Numerical Columns\n",
    "# Select only numerical columns (int64 and float64)\n",
    "numerical_columns = data_cleaned.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "# Step 2: Exclude binary or categorical columns from scaling\n",
    "# Define the binary or categorical columns that should not be scaled\n",
    "exclude_columns = ['Dependents', 'Gender', 'Employment Status']  # Add any other binary or categorical columns here\n",
    "# Identify the numerical columns to scale by excluding the binary/categorical columns\n",
    "columns_to_scale = [col for col in numerical_columns if col not in exclude_columns]\n",
    "print(\"Columns to scale: \", columns_to_scale)\n",
    "# Step 3: Normalize the selected columns using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "data_cleaned[columns_to_scale] = scaler.fit_transform(data_cleaned[columns_to_scale])\n",
    "# Step 4: Standardize the selected columns using StandardScaler (if you want to standardize instead of normalize)\n",
    "# scaler = StandardScaler()\n",
    "# data_cleaned[columns_to_scale] = scaler.fit_transform(data_cleaned[columns_to_scale])\n",
    "# The data is now normalized (or standardized if you uncomment the StandardScaler)\n",
    "# Optional: Save the final processed data\n",
    "data_cleaned.to_csv('final_processed_data.csv', index=False)\n",
    "# Check the first few rows of the scaled data\n",
    "print(data_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9400d70c-9c85-40dc-b8e7-c4e73d78fd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466\n",
      "17106\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in 'AttendedBootcamp' and 'BootcampFinish'\n",
    "print(data_cleaned['AttendedBootcamp'].isnull().sum())\n",
    "print(data_cleaned['BootcampFinish'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4016fe0c-184c-461a-891d-d45c882f6e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where 'AttendedBootcamp' or 'BootcampFinish' have NaN values\n",
    "data_cleaned = data_cleaned.dropna(subset=['AttendedBootcamp', 'BootcampFinish'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c63ea0b2-6392-439e-aafe-55c863c230d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and targets ('AttendedBootcamp' and 'BootcampFinish') again after removing NaNs\n",
    "X = data_cleaned.drop(columns=['AttendedBootcamp', 'BootcampFinish'])  # Features\n",
    "y_attend = data_cleaned['AttendedBootcamp']  # Target 1: Attend Bootcamp\n",
    "y_finish = data_cleaned['BootcampFinish']  # Target 2: Finish Bootcamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d477b819-0fff-4e96-800f-fddadee0714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split data for 'AttendedBootcamp' prediction with stratified sampling\n",
    "X_train_attend, X_test_attend, y_train_attend, y_test_attend = train_test_split(X, y_attend, test_size=0.3, stratify=y_attend, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b7fbf5f0-3841-4522-ad07-6e97e284ccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for 'BootcampFinish' prediction with stratified sampling\n",
    "X_train_finish, X_test_finish, y_train_finish, y_test_finish = train_test_split(X, y_finish, test_size=0.3, stratify=y_finish, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d8349c75-0429-4a04-bb14-5764eb197c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_attend = pd.concat([X_train_attend, y_train_attend], axis=1)\n",
    "test_attend = pd.concat([X_test_attend, y_test_attend], axis=1)\n",
    "train_attend['Set'] = 'Train'\n",
    "test_attend['Set'] = 'Test'\n",
    "combined_attend = pd.concat([train_attend, test_attend])\n",
    "combined_attend.to_csv('attended_bootcamp_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d37677c6-c591-4472-9484-d7d18ecc9814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 'BootcampFinish' target\n",
    "train_finish = pd.concat([X_train_finish, y_train_finish], axis=1)\n",
    "test_finish = pd.concat([X_test_finish, y_test_finish], axis=1)\n",
    "train_finish['Set'] = 'Train'\n",
    "test_finish['Set'] = 'Test'\n",
    "combined_finish = pd.concat([train_finish, test_finish])\n",
    "combined_finish.to_csv('bootcamp_finish_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e0d7eb-0308-4345-b939-35d11afb553f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f3e0cbcf-d7a5-4ed1-ba98-0ba5ac1f430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths for each member (you can modify these paths as needed)\n",
    "path_ayana = \"datasets/ayana/\"\n",
    "path_roberta = \"datasets/roberta/\"\n",
    "path_dom = \"datasets/dom/\"\n",
    "path_phillip = \"datasets/phillip/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d1028b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7968f8b9-7d2b-4209-93b3-466be824f3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories if they don't exist\n",
    "os.makedirs(path_ayana, exist_ok=True)\n",
    "os.makedirs(path_roberta, exist_ok=True)\n",
    "os.makedirs(path_dom, exist_ok=True)\n",
    "os.makedirs(path_phillip, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "be798ed2-4fa7-4341-862f-1ec0d610459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the paths exist (if necessary)\n",
    "# For Ayana: Logistic Regression & Decision Trees (AttendedBootcamp and BootcampFinish)\n",
    "# Export Ayana's training and test datasets for AttendedBootcamp\n",
    "X_train_attend.to_csv(path_ayana + \"X_train_attend.csv\", index=False)\n",
    "y_train_attend.to_csv(path_ayana + \"y_train_attend.csv\", index=False)\n",
    "X_test_attend.to_csv(path_ayana + \"X_test_attend.csv\", index=False)\n",
    "y_test_attend.to_csv(path_ayana + \"y_test_attend.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "608b26e0-ce41-448e-8a33-caeeb36d8020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Ayana's training and test datasets for BootcampFinish\n",
    "X_train_finish.to_csv(path_ayana + \"X_train_finish.csv\", index=False)\n",
    "y_train_finish.to_csv(path_ayana + \"y_train_finish.csv\", index=False)\n",
    "X_test_finish.to_csv(path_ayana + \"X_test_finish.csv\", index=False)\n",
    "y_test_finish.to_csv(path_ayana + \"y_test_finish.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a5110d24-9a6e-4926-a571-eb54a1635556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "787dc1c4-4baa-4f5b-bd69-482cbf013658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Roberta: Random Forest\n",
    "X_train_attend.to_csv(path_roberta + \"X_train_attend.csv\", index=False)\n",
    "y_train_attend.to_csv(path_roberta + \"y_train_attend.csv\", index=False)\n",
    "X_test_attend.to_csv(path_roberta + \"X_test_attend.csv\", index=False)\n",
    "y_test_attend.to_csv(path_roberta + \"y_test_attend.csv\", index=False)\n",
    "X_train_finish.to_csv(path_roberta + \"X_train_finish.csv\", index=False)\n",
    "y_train_finish.to_csv(path_roberta + \"y_train_finish.csv\", index=False)\n",
    "X_test_finish.to_csv(path_roberta + \"X_test_finish.csv\", index=False)\n",
    "y_test_finish.to_csv(path_roberta + \"y_test_finish.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b3828d24-e230-4442-ad53-22128c244e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Dom: SVM & KNN\n",
    "X_train_attend.to_csv(path_dom + \"X_train_attend.csv\", index=False)\n",
    "y_train_attend.to_csv(path_dom + \"y_train_attend.csv\", index=False)\n",
    "X_test_attend.to_csv(path_dom + \"X_test_attend.csv\", index=False)\n",
    "y_test_attend.to_csv(path_dom + \"y_test_attend.csv\", index=False)\n",
    "X_train_finish.to_csv(path_dom + \"X_train_finish.csv\", index=False)\n",
    "y_train_finish.to_csv(path_dom + \"y_train_finish.csv\", index=False)\n",
    "X_test_finish.to_csv(path_dom + \"X_test_finish.csv\", index=False)\n",
    "y_test_finish.to_csv(path_dom + \"y_test_finish.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "20933319-45de-432f-9152-e34a56406d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Phillip: XGBoost & LightGBM\n",
    "X_train_attend.to_csv(path_phillip + \"X_train_attend.csv\", index=False)\n",
    "y_train_attend.to_csv(path_phillip + \"y_train_attend.csv\", index=False)\n",
    "X_test_attend.to_csv(path_phillip + \"X_test_attend.csv\", index=False)\n",
    "y_test_attend.to_csv(path_phillip + \"y_test_attend.csv\", index=False)\n",
    "X_train_finish.to_csv(path_phillip + \"X_train_finish.csv\", index=False)\n",
    "y_train_finish.to_csv(path_phillip + \"y_train_finish.csv\", index=False)\n",
    "X_test_finish.to_csv(path_phillip + \"X_test_finish.csv\", index=False)\n",
    "y_test_finish.to_csv(path_phillip + \"y_test_finish.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1d3fc327-6f64-4618-af60-38191ebaa9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can export the clean dataset for each member as well\n",
    "data_cleaned.to_csv(path_ayana + \"clean_dataset.csv\", index=False)\n",
    "data_cleaned.to_csv(path_roberta + \"clean_dataset.csv\", index=False)\n",
    "data_cleaned.to_csv(path_dom + \"clean_dataset.csv\", index=False)\n",
    "data_cleaned.to_csv(path_phillip + \"clean_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d97b75-f364-40c8-9694-bad7f83a3bcb",
   "metadata": {},
   "source": [
    "# Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b7826921-83cd-4213-8fae-c72acbaaf0f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                    0.159091\n",
       "BootcampLoanYesNo      0.006684\n",
       "BootcampName           0.129679\n",
       "BootcampRecommend      0.012032\n",
       "ChildrenNumber         0.871658\n",
       "                         ...   \n",
       "YouTubeMIT             0.851604\n",
       "YouTubeMozillaHacks    0.963904\n",
       "YouTubeOther           0.925134\n",
       "YouTubeSimplilearn     0.983957\n",
       "YouTubeTheNewBoston    0.897059\n",
       "Length: 134, dtype: float64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the percentage of null values in each column\n",
    "X_train_attend.isna().sum()/len(X_train_attend)\n",
    "X_train_finish.isna().sum()/len(X_train_finish)\n",
    "#X_train.isna().sum()/len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0757d3b6-377c-4f5d-9e2d-9592a6d8bd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore each column with missing values to determine the best fill strategy\n",
    "# First the job column\n",
    "X_train['<Choose Column>'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47db665-338d-4599-a7f9-01459a566fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
