{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "964c9180-6e36-4e2b-bf3e-46f2ee4dd86f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\philk\\AppData\\Local\\Temp\\ipykernel_92592\\2659837848.py:14: DtypeWarning: Columns (17,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data_cleaned = pd.read_csv('./clean-data/2017-fCC-New-Coders-Survey-Data.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>AttendedBootcamp</th>\n",
       "      <th>BootcampFinish</th>\n",
       "      <th>BootcampLoanYesNo</th>\n",
       "      <th>BootcampName</th>\n",
       "      <th>BootcampRecommend</th>\n",
       "      <th>ChildrenNumber</th>\n",
       "      <th>CityPopulation</th>\n",
       "      <th>CodeEventConferences</th>\n",
       "      <th>CodeEventDjangoGirls</th>\n",
       "      <th>...</th>\n",
       "      <th>YouTubeFCC</th>\n",
       "      <th>YouTubeFunFunFunction</th>\n",
       "      <th>YouTubeGoogleDev</th>\n",
       "      <th>YouTubeLearnCode</th>\n",
       "      <th>YouTubeLevelUpTuts</th>\n",
       "      <th>YouTubeMIT</th>\n",
       "      <th>YouTubeMozillaHacks</th>\n",
       "      <th>YouTubeOther</th>\n",
       "      <th>YouTubeSimplilearn</th>\n",
       "      <th>YouTubeTheNewBoston</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>more than 1 million</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>less than 100,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>more than 1 million</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>between 100,000 and 1 million</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>between 100,000 and 1 million</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  AttendedBootcamp  BootcampFinish  BootcampLoanYesNo BootcampName  \\\n",
       "0  27.0               0.0             NaN                NaN          NaN   \n",
       "1  34.0               0.0             NaN                NaN          NaN   \n",
       "2  21.0               0.0             NaN                NaN          NaN   \n",
       "3  26.0               0.0             NaN                NaN          NaN   \n",
       "4  20.0               0.0             NaN                NaN          NaN   \n",
       "\n",
       "   BootcampRecommend  ChildrenNumber                 CityPopulation  \\\n",
       "0                NaN             NaN            more than 1 million   \n",
       "1                NaN             NaN              less than 100,000   \n",
       "2                NaN             NaN            more than 1 million   \n",
       "3                NaN             NaN  between 100,000 and 1 million   \n",
       "4                NaN             NaN  between 100,000 and 1 million   \n",
       "\n",
       "   CodeEventConferences  CodeEventDjangoGirls  ...  YouTubeFCC  \\\n",
       "0                   NaN                   NaN  ...         NaN   \n",
       "1                   NaN                   NaN  ...         1.0   \n",
       "2                   NaN                   NaN  ...         NaN   \n",
       "3                   NaN                   NaN  ...         1.0   \n",
       "4                   NaN                   NaN  ...         NaN   \n",
       "\n",
       "   YouTubeFunFunFunction  YouTubeGoogleDev  YouTubeLearnCode  \\\n",
       "0                    NaN               NaN               NaN   \n",
       "1                    NaN               NaN               NaN   \n",
       "2                    NaN               NaN               1.0   \n",
       "3                    1.0               NaN               NaN   \n",
       "4                    NaN               NaN               NaN   \n",
       "\n",
       "   YouTubeLevelUpTuts  YouTubeMIT  YouTubeMozillaHacks YouTubeOther  \\\n",
       "0                 NaN         NaN                  NaN          NaN   \n",
       "1                 NaN         NaN                  NaN          NaN   \n",
       "2                 1.0         NaN                  NaN          NaN   \n",
       "3                 1.0         NaN                  NaN          NaN   \n",
       "4                 NaN         NaN                  NaN          NaN   \n",
       "\n",
       "   YouTubeSimplilearn  YouTubeTheNewBoston  \n",
       "0                 NaN                  NaN  \n",
       "1                 NaN                  NaN  \n",
       "2                 NaN                  NaN  \n",
       "3                 NaN                  NaN  \n",
       "4                 NaN                  NaN  \n",
       "\n",
       "[5 rows x 136 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import os\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb# Encode the y data with the label encoder\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_cleaned = pd.read_csv('./clean-data/2017-fCC-New-Coders-Survey-Data.csv')\n",
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b81d378d-d32b-489f-8c58-9bb2d0277bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18175 entries, 0 to 18174\n",
      "Columns: 136 entries, Age to YouTubeTheNewBoston\n",
      "dtypes: float64(105), object(31)\n",
      "memory usage: 18.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data_cleaned.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a92d086-483f-4007-a36c-8341423c77f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                    float64\n",
       "AttendedBootcamp       float64\n",
       "BootcampFinish         float64\n",
       "BootcampLoanYesNo      float64\n",
       "BootcampName            object\n",
       "                        ...   \n",
       "YouTubeMIT             float64\n",
       "YouTubeMozillaHacks    float64\n",
       "YouTubeOther            object\n",
       "YouTubeSimplilearn     float64\n",
       "YouTubeTheNewBoston    float64\n",
       "Length: 136, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d5cd919-c01c-44bf-92af-2af468aea6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age                     2808\n",
      "AttendedBootcamp         466\n",
      "BootcampFinish         17106\n",
      "BootcampLoanYesNo      17096\n",
      "BootcampName           17226\n",
      "                       ...  \n",
      "YouTubeMIT             14848\n",
      "YouTubeMozillaHacks    17553\n",
      "YouTubeOther           17027\n",
      "YouTubeSimplilearn     17974\n",
      "YouTubeTheNewBoston    15215\n",
      "Length: 136, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values = data_cleaned.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a950b098-eea6-49ed-9858-78fa4a174801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Handle missing values by removing rows with missing values\n",
    "data_cleaned = data_cleaned.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9c12f94-d959-403d-97fe-baf52052d514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Remove duplicate records\n",
    "data_cleaned = data_cleaned.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f45a6054-746b-49bc-ad8a-bfdc15fd7ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Merge Columns\n",
    "# Merge 'Do you financially support any dependents?' and 'Do you have children?' into 'Dependents'\n",
    "def merge_dependents(row):\n",
    "    # Check if both columns exist and apply logic\n",
    "    if 'Do you financially support any dependents?' in row.index and 'Do you have children?' in row.index:\n",
    "        if row['Do you financially support any dependents?'] == 'Yes' or row['Do you have children?'] == 'Yes':\n",
    "            return 'Yes'\n",
    "        else:\n",
    "            return 'No'\n",
    "    return np.nan  # Return NaN if columns do not exist\n",
    "# Apply the function to create the 'Dependents' column\n",
    "data_cleaned['Dependents'] = data_cleaned.apply(merge_dependents, axis=1)\n",
    "# Merge 'Do you have student loan debt?', 'Do you have any debt?', and 'Do you have a home mortgage?' into 'Debt status category'\n",
    "def merge_debt(row):\n",
    "    if 'Do you have student loan debt?' in row.index and row['Do you have student loan debt?'] == 'Yes':\n",
    "        return 'Student Loan'\n",
    "    elif 'Do you have a home mortgage?' in row.index and row['Do you have a home mortgage?'] == 'Yes':\n",
    "        return 'Mortgage'\n",
    "    elif 'Do you have any debt?' in row.index and row['Do you have any debt?'] == 'Yes':\n",
    "        return 'Other Debt'\n",
    "    else:\n",
    "        return 'No Debt'\n",
    "# Apply the function to create the 'Debt status category' column\n",
    "data_cleaned['Debt status category'] = data_cleaned.apply(merge_debt, axis=1)\n",
    "# Merge 'Other' columns ('Other' gender, employment/school, career)\n",
    "def merge_other(row):\n",
    "    if 'Other' in row.index and pd.notna(row['Other']):\n",
    "        return row['Other']\n",
    "    elif 'Other.1' in row.index and pd.notna(row['Other.1']):\n",
    "        return row['Other.1']\n",
    "    elif 'Other.2' in row.index and pd.notna(row['Other.2']):\n",
    "        return row['Other.2']\n",
    "    return np.nan\n",
    "# Apply the function to merge 'Other' columns\n",
    "data_cleaned['Other'] = data_cleaned.apply(merge_other, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fe6e90c-6311-4d3e-aa66-1ff67977e5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Remove irrelevant columns\n",
    "columns_to_remove = ['Submit Date (UTC)', 'Start Date (UTC)', 'Network ID', 'Other.1', 'Other.2', 'Other']\n",
    "data_cleaned = data_cleaned.drop(columns=[col for col in columns_to_remove if col in data_cleaned.columns])\n",
    "# Step 5: Handle any inconsistencies in the data (assuming none for now)\n",
    "# The data is now cleaned and ready for machine learning algorithms.\n",
    "# Optional: Save the cleaned data to a new CSV file\n",
    "data_cleaned.to_csv('cleaned_survey_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9b7cd83-0bc0-464b-94f7-aca9bb269d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Remove irrelevant columns if they exist in the dataset\n",
    "columns_to_remove = ['Submit Date (UTC)', 'Start Date (UTC)', 'Network ID', '#', 'Other', 'Other.1', 'Other.2']\n",
    "# Check if each column exists before dropping\n",
    "data_cleaned = data_cleaned.drop(columns=[col for col in columns_to_remove if col in data_cleaned.columns], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1c6fbaa-536c-44ee-b195-d509c1457c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Age, AttendedBootcamp, BootcampFinish, BootcampLoanYesNo, BootcampName, BootcampRecommend, ChildrenNumber, CityPopulation, CodeEventConferences, CodeEventDjangoGirls, CodeEventFCC, CodeEventGameJam, CodeEventGirlDev, CodeEventHackathons, CodeEventMeetup, CodeEventNodeSchool, CodeEventNone, CodeEventOther, CodeEventRailsBridge, CodeEventRailsGirls, CodeEventStartUpWknd, CodeEventWkdBootcamps, CodeEventWomenCode, CodeEventWorkshops, CommuteTime, CountryCitizen, CountryLive, EmploymentField, EmploymentFieldOther, EmploymentStatus, EmploymentStatusOther, ExpectedEarning, FinanciallySupporting, FirstDevJob, Gender, GenderOther, HasChildren, HasDebt, HasFinancialDependents, HasHighSpdInternet, HasHomeMortgage, HasServedInMilitary, HasStudentDebt, HomeMortgageOwe, HoursLearning, ID.x, ID.y, Income, IsEthnicMinority, IsReceiveDisabilitiesBenefits, IsSoftwareDev, IsUnderEmployed, JobApplyWhen, JobInterestBackEnd, JobInterestDataEngr, JobInterestDataSci, JobInterestDevOps, JobInterestFrontEnd, JobInterestFullStack, JobInterestGameDev, JobInterestInfoSec, JobInterestMobile, JobInterestOther, JobInterestProjMngr, JobInterestQAEngr, JobInterestUX, JobPref, JobRelocateYesNo, JobRoleInterest, JobWherePref, LanguageAtHome, MaritalStatus, MoneyForLearning, MonthsProgramming, NetworkID, Part1EndTime, Part1StartTime, Part2EndTime, Part2StartTime, PodcastChangeLog, PodcastCodeNewbie, PodcastCodePen, PodcastDevTea, PodcastDotNET, PodcastGiantRobots, PodcastJSAir, PodcastJSJabber, PodcastNone, PodcastOther, PodcastProgThrowdown, PodcastRubyRogues, PodcastSEDaily, PodcastSERadio, PodcastShopTalk, PodcastTalkPython, PodcastTheWebAhead, ResourceCodecademy, ResourceCodeWars, ResourceCoursera, ResourceCSS, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 138 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Display cleaned data (or save it to a new CSV file)\n",
    "print(data_cleaned.head())  # Display the first few rows\n",
    "# If you want to save the cleaned data to a new file\n",
    "data_cleaned.to_csv('cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "919dad59-bfc9-46b8-907a-58b91aac805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Label Encoding for small categories and ordinal features\n",
    "label_encoder = LabelEncoder()\n",
    "# Label encode Gender (if binary or small categories)\n",
    "if 'Gender' in data_cleaned.columns:\n",
    "    data_cleaned['Gender_Encoded'] = label_encoder.fit_transform(data_cleaned['Gender'])\n",
    "# Label encode Degree Level (ordinal)\n",
    "if 'Degree Level' in data_cleaned.columns:\n",
    "    data_cleaned['Degree_Level_Encoded'] = label_encoder.fit_transform(data_cleaned['Degree Level'])\n",
    "# Label encode Employment Status\n",
    "if 'Employment Status' in data_cleaned.columns:\n",
    "    data_cleaned['Employment_Status_Encoded'] = label_encoder.fit_transform(data_cleaned['Employment Status'])\n",
    "# Label encode Student Loan Debt (Yes/No or binary)\n",
    "if 'Do you have student loan debt?' in data_cleaned.columns:\n",
    "    data_cleaned['Student_Loan_Debt_Encoded'] = label_encoder.fit_transform(data_cleaned['Do you have student loan debt?'])\n",
    "# Label encode Family Responsibilities (Yes/No for dependents, children)\n",
    "if 'Dependents' in data_cleaned.columns:\n",
    "    data_cleaned['Dependents_Encoded'] = label_encoder.fit_transform(data_cleaned['Dependents'])\n",
    "# Step 2: One-Hot Encoding for unordered categorical variables\n",
    "# One-hot encode Country of Residence\n",
    "if 'Country of Residence' in data_cleaned.columns:\n",
    "    data_cleaned = pd.get_dummies(data_cleaned, columns=['Country of Residence'], prefix='Country')\n",
    "# One-hot encode Citizenship\n",
    "if 'Citizenship' in data_cleaned.columns:\n",
    "    data_cleaned = pd.get_dummies(data_cleaned, columns=['Citizenship'], prefix='Citizenship')\n",
    "# One-hot encode Job Roles\n",
    "if 'Job Roles' in data_cleaned.columns:\n",
    "    data_cleaned = pd.get_dummies(data_cleaned, columns=['Job Roles'], prefix='Job_Role')\n",
    "# One-hot encode Field of Study\n",
    "if 'Field of Study' in data_cleaned.columns:\n",
    "    data_cleaned = pd.get_dummies(data_cleaned, columns=['Field of Study'], prefix='Field_Study')\n",
    "# One-hot encode Learning Preferences\n",
    "if 'Learning Preferences' in data_cleaned.columns:\n",
    "    data_cleaned = pd.get_dummies(data_cleaned, columns=['Learning Preferences'], prefix='Learning_Pref')\n",
    "# One-hot encode Coding Events/Workshops\n",
    "if 'Coding Events/Workshops' in data_cleaned.columns:\n",
    "    data_cleaned = pd.get_dummies(data_cleaned, columns=['Coding Events/Workshops'], prefix='Coding_Event')\n",
    "# One-hot encode Employment Type Preferences\n",
    "if 'Employment Type Preferences' in data_cleaned.columns:\n",
    "    data_cleaned = pd.get_dummies(data_cleaned, columns=['Employment Type Preferences'], prefix='Employment_Type')\n",
    "# Optional: Step 3: Handling High-Cardinality Features\n",
    "# For very high-cardinality categorical features like 'Country', if dimensionality becomes an issue,\n",
    "# consider using binary encoding from the 'category_encoders' library.\n",
    "# Example: Using binary encoding for 'Country' feature with many categories\n",
    "# Install the category_encoders package if needed:\n",
    "# !pip install category_encoders\n",
    "# from category_encoders import BinaryEncoder\n",
    "# encoder = BinaryEncoder(cols=['Country'])\n",
    "# data_cleaned = encoder.fit_transform(data_cleaned)\n",
    "# Save the encoded dataset to a new CSV file\n",
    "data_cleaned.to_csv('encoded_survey_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74c7a2ca-ffe3-4ad4-96e5-ee8e455ea510",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\philk\\AppData\\Local\\Temp\\ipykernel_92592\\3691866491.py:3: DtypeWarning: Columns (17,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data_cleaned = pd.read_csv('./clean-data/2017-fCC-New-Coders-Survey-Data.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to scale:  ['Age', 'AttendedBootcamp', 'BootcampFinish', 'BootcampLoanYesNo', 'BootcampRecommend', 'ChildrenNumber', 'CodeEventConferences', 'CodeEventDjangoGirls', 'CodeEventFCC', 'CodeEventGameJam', 'CodeEventGirlDev', 'CodeEventHackathons', 'CodeEventMeetup', 'CodeEventNodeSchool', 'CodeEventNone', 'CodeEventRailsBridge', 'CodeEventRailsGirls', 'CodeEventStartUpWknd', 'CodeEventWkdBootcamps', 'CodeEventWomenCode', 'CodeEventWorkshops', 'ExpectedEarning', 'FinanciallySupporting', 'FirstDevJob', 'HasChildren', 'HasDebt', 'HasFinancialDependents', 'HasHighSpdInternet', 'HasHomeMortgage', 'HasServedInMilitary', 'HasStudentDebt', 'HomeMortgageOwe', 'HoursLearning', 'Income', 'IsEthnicMinority', 'IsReceiveDisabilitiesBenefits', 'IsSoftwareDev', 'IsUnderEmployed', 'JobInterestBackEnd', 'JobInterestDataEngr', 'JobInterestDataSci', 'JobInterestDevOps', 'JobInterestFrontEnd', 'JobInterestFullStack', 'JobInterestGameDev', 'JobInterestInfoSec', 'JobInterestMobile', 'JobInterestProjMngr', 'JobInterestQAEngr', 'JobInterestUX', 'JobRelocateYesNo', 'MoneyForLearning', 'MonthsProgramming', 'PodcastChangeLog', 'PodcastCodeNewbie', 'PodcastCodePen', 'PodcastDevTea', 'PodcastDotNET', 'PodcastGiantRobots', 'PodcastJSAir', 'PodcastJSJabber', 'PodcastNone', 'PodcastProgThrowdown', 'PodcastRubyRogues', 'PodcastSEDaily', 'PodcastSERadio', 'PodcastShopTalk', 'PodcastTalkPython', 'PodcastTheWebAhead', 'ResourceCodecademy', 'ResourceCodeWars', 'ResourceCoursera', 'ResourceCSS', 'ResourceEdX', 'ResourceEgghead', 'ResourceFCC', 'ResourceHackerRank', 'ResourceKA', 'ResourceLynda', 'ResourceMDN', 'ResourceOdinProj', 'ResourcePluralSight', 'ResourceSkillcrush', 'ResourceSO', 'ResourceTreehouse', 'ResourceUdacity', 'ResourceUdemy', 'ResourceW3S', 'StudentDebtOwe', 'YouTubeCodeCourse', 'YouTubeCodingTrain', 'YouTubeCodingTut360', 'YouTubeComputerphile', 'YouTubeDerekBanas', 'YouTubeDevTips', 'YouTubeEngineeredTruth', 'YouTubeFCC', 'YouTubeFunFunFunction', 'YouTubeGoogleDev', 'YouTubeLearnCode', 'YouTubeLevelUpTuts', 'YouTubeMIT', 'YouTubeMozillaHacks', 'YouTubeSimplilearn', 'YouTubeTheNewBoston']\n",
      "        Age  AttendedBootcamp  BootcampFinish  BootcampLoanYesNo BootcampName  \\\n",
      "0  0.300000               0.0             NaN                NaN          NaN   \n",
      "1  0.377778               0.0             NaN                NaN          NaN   \n",
      "2  0.233333               0.0             NaN                NaN          NaN   \n",
      "3  0.288889               0.0             NaN                NaN          NaN   \n",
      "4  0.222222               0.0             NaN                NaN          NaN   \n",
      "\n",
      "   BootcampRecommend  ChildrenNumber                 CityPopulation  \\\n",
      "0                NaN             NaN            more than 1 million   \n",
      "1                NaN             NaN              less than 100,000   \n",
      "2                NaN             NaN            more than 1 million   \n",
      "3                NaN             NaN  between 100,000 and 1 million   \n",
      "4                NaN             NaN  between 100,000 and 1 million   \n",
      "\n",
      "   CodeEventConferences  CodeEventDjangoGirls  ...  YouTubeFCC  \\\n",
      "0                   NaN                   NaN  ...         NaN   \n",
      "1                   NaN                   NaN  ...         0.0   \n",
      "2                   NaN                   NaN  ...         NaN   \n",
      "3                   NaN                   NaN  ...         0.0   \n",
      "4                   NaN                   NaN  ...         NaN   \n",
      "\n",
      "   YouTubeFunFunFunction  YouTubeGoogleDev  YouTubeLearnCode  \\\n",
      "0                    NaN               NaN               NaN   \n",
      "1                    NaN               NaN               NaN   \n",
      "2                    NaN               NaN               0.0   \n",
      "3                    0.0               NaN               NaN   \n",
      "4                    NaN               NaN               NaN   \n",
      "\n",
      "   YouTubeLevelUpTuts  YouTubeMIT  YouTubeMozillaHacks YouTubeOther  \\\n",
      "0                 NaN         NaN                  NaN          NaN   \n",
      "1                 NaN         NaN                  NaN          NaN   \n",
      "2                 0.0         NaN                  NaN          NaN   \n",
      "3                 0.0         NaN                  NaN          NaN   \n",
      "4                 NaN         NaN                  NaN          NaN   \n",
      "\n",
      "   YouTubeSimplilearn  YouTubeTheNewBoston  \n",
      "0                 NaN                  NaN  \n",
      "1                 NaN                  NaN  \n",
      "2                 NaN                  NaN  \n",
      "3                 NaN                  NaN  \n",
      "4                 NaN                  NaN  \n",
      "\n",
      "[5 rows x 136 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# Load the dataset (replace with your actual file path)\n",
    "data_cleaned = pd.read_csv('./clean-data/2017-fCC-New-Coders-Survey-Data.csv')\n",
    "# Step 1: Identify Numerical Columns\n",
    "# Select only numerical columns (int64 and float64)\n",
    "numerical_columns = data_cleaned.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "# Step 2: Exclude binary or categorical columns from scaling\n",
    "# Define the binary or categorical columns that should not be scaled\n",
    "exclude_columns = ['Dependents', 'Gender', 'Employment Status']  # Add any other binary or categorical columns here\n",
    "# Identify the numerical columns to scale by excluding the binary/categorical columns\n",
    "columns_to_scale = [col for col in numerical_columns if col not in exclude_columns]\n",
    "print(\"Columns to scale: \", columns_to_scale)\n",
    "# Step 3: Normalize the selected columns using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "data_cleaned[columns_to_scale] = scaler.fit_transform(data_cleaned[columns_to_scale])\n",
    "# Step 4: Standardize the selected columns using StandardScaler (if you want to standardize instead of normalize)\n",
    "# scaler = StandardScaler()\n",
    "# data_cleaned[columns_to_scale] = scaler.fit_transform(data_cleaned[columns_to_scale])\n",
    "# The data is now normalized (or standardized if you uncomment the StandardScaler)\n",
    "# Optional: Save the final processed data\n",
    "data_cleaned.to_csv('final_processed_data.csv', index=False)\n",
    "# Check the first few rows of the scaled data\n",
    "print(data_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9400d70c-9c85-40dc-b8e7-c4e73d78fd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466\n",
      "17106\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in 'AttendedBootcamp' and 'BootcampFinish'\n",
    "print(data_cleaned['AttendedBootcamp'].isnull().sum())\n",
    "print(data_cleaned['BootcampFinish'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4016fe0c-184c-461a-891d-d45c882f6e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where 'AttendedBootcamp' or 'BootcampFinish' have NaN values\n",
    "data_cleaned = data_cleaned.dropna(subset=['AttendedBootcamp', 'BootcampFinish'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c63ea0b2-6392-439e-aafe-55c863c230d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and targets ('AttendedBootcamp' and 'BootcampFinish') again after removing NaNs\n",
    "X = data_cleaned.drop(columns=['AttendedBootcamp', 'BootcampFinish'])  # Features\n",
    "y_attend = data_cleaned['AttendedBootcamp']  # Target 1: Attend Bootcamp\n",
    "y_finish = data_cleaned['BootcampFinish']  # Target 2: Finish Bootcamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d477b819-0fff-4e96-800f-fddadee0714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split data for 'AttendedBootcamp' prediction with stratified sampling\n",
    "X_train_attend, X_test_attend, y_train_attend, y_test_attend = train_test_split(X, y_attend, test_size=0.3, stratify=y_attend, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7fbf5f0-3841-4522-ad07-6e97e284ccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for 'BootcampFinish' prediction with stratified sampling\n",
    "X_train_finish, X_test_finish, y_train_finish, y_test_finish = train_test_split(X, y_finish, test_size=0.3, stratify=y_finish, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3e0cbcf-d7a5-4ed1-ba98-0ba5ac1f430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths for each member (you can modify these paths as needed)\n",
    "path_ayana = \"datasets/ayana/\"\n",
    "path_roberta = \"datasets/roberta/\"\n",
    "path_dom = \"datasets/dom/\"\n",
    "path_phillip = \"datasets/phillip/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7968f8b9-7d2b-4209-93b3-466be824f3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories if they don't exist\n",
    "os.makedirs(path_ayana, exist_ok=True)\n",
    "os.makedirs(path_roberta, exist_ok=True)\n",
    "os.makedirs(path_dom, exist_ok=True)\n",
    "os.makedirs(path_phillip, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be798ed2-4fa7-4341-862f-1ec0d610459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ensure the paths exist (if necessary)\n",
    "# # For Ayana: Logistic Regression & Decision Trees (AttendedBootcamp and BootcampFinish)\n",
    "# # Export Ayana's training and test datasets for AttendedBootcamp\n",
    "# X_train_attend.to_csv(path_ayana + \"X_train_attend.csv\", index=False)\n",
    "# y_train_attend.to_csv(path_ayana + \"y_train_attend.csv\", index=False)\n",
    "# X_test_attend.to_csv(path_ayana + \"X_test_attend.csv\", index=False)\n",
    "# y_test_attend.to_csv(path_ayana + \"y_test_attend.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "608b26e0-ce41-448e-8a33-caeeb36d8020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export Ayana's training and test datasets for BootcampFinish\n",
    "# X_train_finish.to_csv(path_ayana + \"X_train_finish.csv\", index=False)\n",
    "# y_train_finish.to_csv(path_ayana + \"y_train_finish.csv\", index=False)\n",
    "# X_test_finish.to_csv(path_ayana + \"X_test_finish.csv\", index=False)\n",
    "# y_test_finish.to_csv(path_ayana + \"y_test_finish.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5110d24-9a6e-4926-a571-eb54a1635556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "787dc1c4-4baa-4f5b-bd69-482cbf013658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Roberta: Random Forest\n",
    "X_train_attend.to_csv(path_roberta + \"X_train_attend.csv\", index=False)\n",
    "y_train_attend.to_csv(path_roberta + \"y_train_attend.csv\", index=False)\n",
    "X_test_attend.to_csv(path_roberta + \"X_test_attend.csv\", index=False)\n",
    "y_test_attend.to_csv(path_roberta + \"y_test_attend.csv\", index=False)\n",
    "X_train_finish.to_csv(path_roberta + \"X_train_finish.csv\", index=False)\n",
    "y_train_finish.to_csv(path_roberta + \"y_train_finish.csv\", index=False)\n",
    "X_test_finish.to_csv(path_roberta + \"X_test_finish.csv\", index=False)\n",
    "y_test_finish.to_csv(path_roberta + \"y_test_finish.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3828d24-e230-4442-ad53-22128c244e92",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For Dom: SVM & KNN\n",
    "#X_train_attend.to_csv(path_dom + \"X_train_attend.csv\", index=False)\n",
    "#y_train_attend.to_csv(path_dom + \"y_train_attend.csv\", index=False)\n",
    "# X_test_attend.to_csv(path_dom + \"X_test_attend.csv\", index=False)\n",
    "# y_test_attend.to_csv(path_dom + \"y_test_attend.csv\", index=False)\n",
    "# X_train_finish.to_csv(path_dom + \"X_train_finish.csv\", index=False)\n",
    "# y_train_finish.to_csv(path_dom + \"y_train_finish.csv\", index=False)\n",
    "# X_test_finish.to_csv(path_dom + \"X_test_finish.csv\", index=False)\n",
    "# y_test_finish.to_csv(path_dom + \"y_test_finish.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20933319-45de-432f-9152-e34a56406d20",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d3fc327-6f64-4618-af60-38191ebaa9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can export the clean dataset for each member as well\n",
    "data_cleaned.to_csv(path_ayana + \"clean_dataset.csv\", index=False)\n",
    "data_cleaned.to_csv(path_roberta + \"clean_dataset.csv\", index=False)\n",
    "data_cleaned.to_csv(path_dom + \"clean_dataset.csv\", index=False)\n",
    "data_cleaned.to_csv(path_phillip + \"clean_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee367834-0a84-4a84-bbb4-638bf30c9e67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3cc921e1-9827-4cd8-bcd5-d71d3006d05c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "# RandomForest DATA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b439b328-97c0-4c32-86ea-086a37dab31c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Import\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a560e8d2-f5b4-4a14-8096-cb781d8596df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>BootcampLoanYesNo</th>\n",
       "      <th>BootcampName</th>\n",
       "      <th>BootcampRecommend</th>\n",
       "      <th>ChildrenNumber</th>\n",
       "      <th>CityPopulation</th>\n",
       "      <th>CodeEventConferences</th>\n",
       "      <th>CodeEventDjangoGirls</th>\n",
       "      <th>CodeEventFCC</th>\n",
       "      <th>CodeEventGameJam</th>\n",
       "      <th>...</th>\n",
       "      <th>YouTubeFCC</th>\n",
       "      <th>YouTubeFunFunFunction</th>\n",
       "      <th>YouTubeGoogleDev</th>\n",
       "      <th>YouTubeLearnCode</th>\n",
       "      <th>YouTubeLevelUpTuts</th>\n",
       "      <th>YouTubeMIT</th>\n",
       "      <th>YouTubeMozillaHacks</th>\n",
       "      <th>YouTubeOther</th>\n",
       "      <th>YouTubeSimplilearn</th>\n",
       "      <th>YouTubeTheNewBoston</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15799</th>\n",
       "      <td>0.288889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>more than 1 million</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7643</th>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>General Assembly</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>more than 1 million</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11330</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>We Can Code IT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14366</th>\n",
       "      <td>0.288889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Science to Data Science</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>less than 100,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12291</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hack Reactor</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9358</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>codeU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>more than 1 million</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Logit Academy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>between 100,000 and 1 million</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10408</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Academic Work Academy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1873</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Galvanize</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>between 100,000 and 1 million</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5315</th>\n",
       "      <td>0.244444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Free Code Camp is not a bootcamp - please scro...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>more than 1 million</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>321 rows × 134 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Age  BootcampLoanYesNo  \\\n",
       "15799  0.288889                0.0   \n",
       "7643   0.266667                0.0   \n",
       "11330       NaN                1.0   \n",
       "14366  0.288889                1.0   \n",
       "12291       NaN                1.0   \n",
       "...         ...                ...   \n",
       "9358   0.300000                0.0   \n",
       "804    0.333333                0.0   \n",
       "10408       NaN                0.0   \n",
       "1873   0.533333                0.0   \n",
       "5315   0.244444                0.0   \n",
       "\n",
       "                                            BootcampName  BootcampRecommend  \\\n",
       "15799                                                NaN                1.0   \n",
       "7643                                    General Assembly                1.0   \n",
       "11330                                     We Can Code IT                1.0   \n",
       "14366                            Science to Data Science                1.0   \n",
       "12291                                       Hack Reactor                1.0   \n",
       "...                                                  ...                ...   \n",
       "9358                                               codeU                0.0   \n",
       "804                                        Logit Academy                0.0   \n",
       "10408                              Academic Work Academy                1.0   \n",
       "1873                                           Galvanize                1.0   \n",
       "5315   Free Code Camp is not a bootcamp - please scro...                1.0   \n",
       "\n",
       "       ChildrenNumber                 CityPopulation  CodeEventConferences  \\\n",
       "15799             NaN            more than 1 million                   NaN   \n",
       "7643              NaN            more than 1 million                   0.0   \n",
       "11330             NaN                            NaN                   NaN   \n",
       "14366             NaN              less than 100,000                   NaN   \n",
       "12291             NaN                            NaN                   NaN   \n",
       "...               ...                            ...                   ...   \n",
       "9358              NaN            more than 1 million                   NaN   \n",
       "804               NaN  between 100,000 and 1 million                   NaN   \n",
       "10408             NaN                            NaN                   NaN   \n",
       "1873              NaN  between 100,000 and 1 million                   NaN   \n",
       "5315              NaN            more than 1 million                   NaN   \n",
       "\n",
       "       CodeEventDjangoGirls  CodeEventFCC  CodeEventGameJam  ...  YouTubeFCC  \\\n",
       "15799                   NaN           NaN               NaN  ...         0.0   \n",
       "7643                    NaN           NaN               NaN  ...         NaN   \n",
       "11330                   NaN           NaN               NaN  ...         NaN   \n",
       "14366                   NaN           0.0               NaN  ...         0.0   \n",
       "12291                   NaN           NaN               NaN  ...         0.0   \n",
       "...                     ...           ...               ...  ...         ...   \n",
       "9358                    NaN           NaN               NaN  ...         NaN   \n",
       "804                     NaN           0.0               NaN  ...         0.0   \n",
       "10408                   NaN           0.0               NaN  ...         NaN   \n",
       "1873                    NaN           0.0               NaN  ...         NaN   \n",
       "5315                    NaN           0.0               NaN  ...         0.0   \n",
       "\n",
       "       YouTubeFunFunFunction  YouTubeGoogleDev  YouTubeLearnCode  \\\n",
       "15799                    NaN               NaN               NaN   \n",
       "7643                     NaN               NaN               NaN   \n",
       "11330                    NaN               NaN               0.0   \n",
       "14366                    NaN               0.0               NaN   \n",
       "12291                    NaN               NaN               NaN   \n",
       "...                      ...               ...               ...   \n",
       "9358                     NaN               NaN               NaN   \n",
       "804                      0.0               NaN               NaN   \n",
       "10408                    NaN               NaN               NaN   \n",
       "1873                     NaN               NaN               NaN   \n",
       "5315                     NaN               NaN               NaN   \n",
       "\n",
       "       YouTubeLevelUpTuts YouTubeMIT  YouTubeMozillaHacks  YouTubeOther  \\\n",
       "15799                 NaN        NaN                  NaN           NaN   \n",
       "7643                  NaN        NaN                  NaN           NaN   \n",
       "11330                 NaN        NaN                  NaN           NaN   \n",
       "14366                 NaN        0.0                  NaN           NaN   \n",
       "12291                 0.0        NaN                  NaN           NaN   \n",
       "...                   ...        ...                  ...           ...   \n",
       "9358                  NaN        NaN                  NaN           NaN   \n",
       "804                   NaN        0.0                  NaN           NaN   \n",
       "10408                 NaN        NaN                  0.0           NaN   \n",
       "1873                  NaN        NaN                  NaN           NaN   \n",
       "5315                  NaN        NaN                  NaN           NaN   \n",
       "\n",
       "       YouTubeSimplilearn  YouTubeTheNewBoston  \n",
       "15799                 NaN                  NaN  \n",
       "7643                  NaN                  NaN  \n",
       "11330                 NaN                  NaN  \n",
       "14366                 NaN                  NaN  \n",
       "12291                 NaN                  0.0  \n",
       "...                   ...                  ...  \n",
       "9358                  NaN                  NaN  \n",
       "804                   NaN                  NaN  \n",
       "10408                 NaN                  NaN  \n",
       "1873                  NaN                  NaN  \n",
       "5315                  NaN                  NaN  \n",
       "\n",
       "[321 rows x 134 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5ff4a463-3f7f-43df-9101-0475276950c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Decision Tree model for finish data\n",
    "dt_model_finish = DecisionTreeClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "66107c01-817c-4fe2-8e8f-ee8ba14320f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical variables to dummy/indicator variables\n",
    "# X_train_finish = pd.get_dummies(X_train_finish) -------------------------------- chnage back if needed 10/29\n",
    "# X_test_finish = pd.get_dummies(X_test_finish)   -------------------------------- chnage back if needed 10/29\n",
    "\n",
    "# Align the columns of train and test sets\n",
    "X_train_finish, X_test_finish = X_train_finish.align(X_test_finish, join='left', axis=1, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4d8cdcdb-8d19-41fa-b47d-65d1cada9778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;cat&#x27;, OneHotEncoder(),\n",
       "                                                  [&#x27;category&#x27;])])),\n",
       "                (&#x27;classifier&#x27;, DecisionTreeClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;cat&#x27;, OneHotEncoder(),\n",
       "                                                  [&#x27;category&#x27;])])),\n",
       "                (&#x27;classifier&#x27;, DecisionTreeClassifier())])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;preprocessor: ColumnTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preprocessor: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;cat&#x27;, OneHotEncoder(), [&#x27;category&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">cat</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;category&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">remainder</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;feature1&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">passthrough</label><div class=\"sk-toggleable__content fitted\"><pre>passthrough</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier()</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('cat', OneHotEncoder(),\n",
       "                                                  ['category'])])),\n",
       "                ('classifier', DecisionTreeClassifier())])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Example data (replace with your actual data)\n",
    "X_train_finish = pd.DataFrame({\n",
    "    'feature1': [1, 2, 3],\n",
    "    'category': ['Coder Camps', 'Coder Camps', 'Other']\n",
    "})\n",
    "y_train_finish = [0, 1, 0]\n",
    "\n",
    "# Create a column transformer to apply one-hot encoding to the categorical column\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), ['category'])  # Apply OneHotEncoder to 'category' column\n",
    "    ],\n",
    "    remainder='passthrough'  # Keep the other columns as they are\n",
    ")\n",
    "\n",
    "# Create a pipeline that first transforms the data and then fits the model\n",
    "dt_model_finish = Pipeline(steps=[\n",
    "    ('preprocessor', column_transformer),  # Preprocessing step\n",
    "    ('classifier', DecisionTreeClassifier())  # Model fitting step\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "dt_model_finish.fit(X_train_finish, y_train_finish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c19128be-90de-497d-a1c4-22873c064fa5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing columns in test data: ['category', 'feature1']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m missing_columns \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m required_columns \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m X_test_finish\u001b[38;5;241m.\u001b[39mcolumns]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_columns:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Handle the missing columns case\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing columns in test data: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_columns\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Missing columns in test data: ['category', 'feature1']"
     ]
    }
   ],
   "source": [
    "# Check if required columns are present in X_test_finish\n",
    "required_columns = ['category', 'feature1']  # List of required columns\n",
    "\n",
    "# Ensure that all required columns are in the test DataFrame\n",
    "missing_columns = [col for col in required_columns if col not in X_test_finish.columns]\n",
    "\n",
    "if missing_columns:\n",
    "    # Handle the missing columns case\n",
    "    raise ValueError(f\"Missing columns in test data: {missing_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e388269e-8ef6-4064-bc9c-4aae4cc5ef22",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "columns are missing: {'category', 'feature1'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m y_pred_finish \u001b[38;5;241m=\u001b[39m dt_model_finish\u001b[38;5;241m.\u001b[39mpredict(X_test_finish)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy (Finish):\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy_score(y_test_finish, y_pred_finish))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:602\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **params)\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _routing_enabled():\n\u001b[0;32m    601\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 602\u001b[0m         Xt \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mtransform(Xt)\n\u001b[0;32m    603\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    605\u001b[0m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    301\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:1003\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[1;34m(self, X, **params)\u001b[0m\n\u001b[0;32m   1001\u001b[0m     diff \u001b[38;5;241m=\u001b[39m all_names \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(column_names)\n\u001b[0;32m   1002\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m diff:\n\u001b[1;32m-> 1003\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns are missing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdiff\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1005\u001b[0m     \u001b[38;5;66;03m# ndarray was used for fitting or transforming, thus we only\u001b[39;00m\n\u001b[0;32m   1006\u001b[0m     \u001b[38;5;66;03m# check that n_features_in_ is consistent\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mValueError\u001b[0m: columns are missing: {'category', 'feature1'}"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Make predictions\n",
    "y_pred_finish = dt_model_finish.predict(X_test_finish)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy (Finish):\", accuracy_score(y_test_finish, y_pred_finish))\n",
    "print(classification_report(y_test_finish, y_pred_finish))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e4123028-e527-47fc-be77-b6346fecae49",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot have number of splits n_splits=5 greater than the number of samples: n_samples=3.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 15\u001b[0m\n\u001b[0;32m     11\u001b[0m grid_search_finish \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mdt_model_finish, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, \n\u001b[0;32m     12\u001b[0m                                    scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Fit the grid search model\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m grid_search_finish\u001b[38;5;241m.\u001b[39mfit(X_train_finish, y_train_finish)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Best parameters for attend data\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Parameters (finish):\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search_finish\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:928\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[0;32m    916\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    917\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    918\u001b[0m         clone(base_estimator),\n\u001b[0;32m    919\u001b[0m         X,\n\u001b[0;32m    920\u001b[0m         y,\n\u001b[0;32m    921\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    922\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    923\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    924\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    925\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    926\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    927\u001b[0m     )\n\u001b[1;32m--> 928\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    929\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    930\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    931\u001b[0m     )\n\u001b[0;32m    932\u001b[0m )\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:370\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    368\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(X)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m n_samples:\n\u001b[1;32m--> 370\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    371\u001b[0m         (\n\u001b[0;32m    372\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot have number of splits n_splits=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m greater\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    373\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m than the number of samples: n_samples=\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    374\u001b[0m         )\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits, n_samples)\n\u001b[0;32m    375\u001b[0m     )\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msplit(X, y, groups):\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot have number of splits n_splits=5 greater than the number of samples: n_samples=3."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "}\n",
    "\n",
    "# Create the grid search object\n",
    "grid_search_finish = GridSearchCV(estimator=dt_model_finish, param_grid=param_grid, \n",
    "                                   scoring='accuracy', cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the grid search model\n",
    "grid_search_finish.fit(X_train_finish, y_train_finish)\n",
    "\n",
    "# Best parameters for attend data\n",
    "print(\"Best Parameters (finish):\", grid_search_finish.best_params_)\n",
    "\n",
    "# Evaluate the best model\n",
    "best_dt_model_finish = grid_search_finish.best_estimator_\n",
    "y_pred_finish_best = dt_model_finish.predict(X_test_finish)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Accuracy (Finish Best):\", accuracy_score(y_test_finish, y_pred_finish_best))\n",
    "print(classification_report(y_test_finish, y_pred_finish_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "039d8638-6f78-43fd-89cc-d9a2d4a0642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the Data \n",
    "path_roberta = \"datasets/roberta/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0d028bf0-8a41-43a5-8f9d-c8070eb7e070",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For Roberta: Random Forest\n",
    "# X_train_attend.to_csv(path_roberta + \"X_train_attend.csv\", index=False)\n",
    "# y_train_attend.to_csv(path_roberta + \"y_train_attend.csv\", index=False)\n",
    "# X_test_attend.to_csv(path_roberta + \"X_test_attend.csv\", index=False)\n",
    "# y_test_attend.to_csv(path_roberta + \"y_test_attend.csv\", index=False)\n",
    "X_train_finish.to_csv(path_roberta + \"X_train_finish.csv\", index=False)\n",
    "y_train_finish_df = pd.DataFrame(y_train_finish)\n",
    "y_train_finish_df.to_csv(path_roberta + \"y_train_finish.csv\", index=False)\n",
    "X_test_finish.to_csv(path_roberta + \"X_test_finish.csv\", index=False)\n",
    "y_test_finish_df = pd.DataFrame(y_test_finish)\n",
    "y_test_finish_df.to_csv(path_roberta + \"y_test_finish.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "58435e7e-08ea-4962-87df-c6eb8f519977",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 14\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ###Train a Random Forest Model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# X_train_finish = pd.read_csv(\"datasets/roberta/X_train_finish.csv\")\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# y_train_finish = pd.read_csv(\"datasets/roberta/y_train_finish.csv\").values.ravel()  \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Align the columns of train and test sets\u001b[39;00m\n\u001b[0;32m     12\u001b[0m X_train_finish, X_test_finish \u001b[38;5;241m=\u001b[39m X_train_finish\u001b[38;5;241m.\u001b[39malign(X_test_finish, join\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m rf_model_finish \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     15\u001b[0m rf_model_finish\u001b[38;5;241m.\u001b[39mfit(X_train_finish, y_train_finish)\n\u001b[0;32m     16\u001b[0m y_pred_finish \u001b[38;5;241m=\u001b[39m rf_model_finish\u001b[38;5;241m.\u001b[39mpredict(X_test_finish)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RandomForestClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# ###Train a Random Forest Model\n",
    "# X_train_finish = pd.read_csv(\"datasets/roberta/X_train_finish.csv\")\n",
    "# y_train_finish = pd.read_csv(\"datasets/roberta/y_train_finish.csv\").values.ravel()  \n",
    "# X_test_finish = pd.read_csv(\"datasets/roberta/X_test_finish.csv\")\n",
    "# y_test_finish = pd.read_csv(\"datasets/roberta/y_test_finish.csv\").values.ravel()\n",
    "\n",
    "# Convert categorical variables to dummy/indicator variables\n",
    "# X_train_finish = pd.get_dummies(X_train_finish)\n",
    "# X_test_finish = pd.get_dummies(X_test_finish)\n",
    "\n",
    "# Align the columns of train and test sets\n",
    "X_train_finish, X_test_finish = X_train_finish.align(X_test_finish, join='left', axis=1, fill_value=0)\n",
    "\n",
    "rf_model_finish = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model_finish.fit(X_train_finish, y_train_finish)\n",
    "y_pred_finish = rf_model_finish.predict(X_test_finish)\n",
    "\n",
    "print(\"Accuracy (Finish):\", accuracy_score(y_test_finish, y_pred_finish))\n",
    "print(classification_report(y_test_finish, y_pred_finish))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "92dc6854-f8db-411a-aeb9-f554d56b0ef6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf_model_finish' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m importance \u001b[38;5;241m=\u001b[39m rf_model_finish\u001b[38;5;241m.\u001b[39mfeature_importances_\n\u001b[0;32m      2\u001b[0m feature_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m\"\u001b[39m: X\u001b[38;5;241m.\u001b[39mcolumns,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGini Importance\u001b[39m\u001b[38;5;124m'\u001b[39m: importance})\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGini Importance\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m feature_df\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rf_model_finish' is not defined"
     ]
    }
   ],
   "source": [
    "importance = rf_model_finish.feature_importances_\n",
    "feature_df = pd.DataFrame({\"Feature\": X.columns,'Gini Importance': importance}).sort_values('Gini Importance', ascending = False)\n",
    "feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d55bcc59-0197-4bbc-a189-105bbc6cdc0c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m feature_10 \u001b[38;5;241m=\u001b[39m feature_df[:\u001b[38;5;241m8\u001b[39m]\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mbarh(feature_10[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m'\u001b[39m], feature_10[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGini Importance\u001b[39m\u001b[38;5;124m'\u001b[39m], color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m, )\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGini Importance\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feature_df' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feature_10 = feature_df[:8]\n",
    "\n",
    "plt.barh(feature_10['Feature'], feature_10['Gini Importance'], color='blue', )\n",
    "plt.xlabel('Gini Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Imp - Bootcamp Graduation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bc4a404c-de47-49ee-9397-69d469b02a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can export the clean dataset for each member as well\n",
    "data_cleaned.to_csv(path_ayana + \"clean_dataset.csv\", index=False)\n",
    "data_cleaned.to_csv(path_roberta + \"clean_dataset.csv\", index=False)\n",
    "data_cleaned.to_csv(path_dom + \"clean_dataset.csv\", index=False)\n",
    "data_cleaned.to_csv(path_phillip + \"clean_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e1304893-03ea-4528-b688-8d4ab92adae0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature1    0.0\n",
       "category    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the percentage of null values in each column\n",
    "X_train_attend.isna().sum()/len(X_train_attend)\n",
    "X_train_finish.isna().sum()/len(X_train_finish)\n",
    "#X_train.isna().sum()/len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a748eac5-2a02-4894-9138-d768c0bfa7f6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[83], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Explore each column with missing values to determine the best fill strategy\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# First the job column\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m X_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<Choose Column>\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Explore each column with missing values to determine the best fill strategy\n",
    "# First the job column\n",
    "X_train['<Choose Column>'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f6ceb2-02a0-45b0-a6d1-2d96b6f9e49a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# XGBoost DATA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c5692586-97a0-40f2-ac46-e5d3d85c6bc2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m y_test_attend\u001b[38;5;241m.\u001b[39mto_csv(path_phillip \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_test_attend.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m X_train_finish\u001b[38;5;241m.\u001b[39mto_csv(path_phillip \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_train_finish.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m----> 7\u001b[0m y_train_finish\u001b[38;5;241m.\u001b[39mto_csv(path_phillip \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_train_finish.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m X_test_finish\u001b[38;5;241m.\u001b[39mto_csv(path_phillip \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_test_finish.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      9\u001b[0m y_test_finish\u001b[38;5;241m.\u001b[39mto_csv(path_phillip \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_test_finish.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'to_csv'"
     ]
    }
   ],
   "source": [
    "# For Phillip: XGBoost & LightGBM\n",
    "X_train_attend.to_csv(path_phillip + \"X_train_attend.csv\", index=False)\n",
    "y_train_attend.to_csv(path_phillip + \"y_train_attend.csv\", index=False)\n",
    "X_test_attend.to_csv(path_phillip + \"X_test_attend.csv\", index=False)\n",
    "y_test_attend.to_csv(path_phillip + \"y_test_attend.csv\", index=False)\n",
    "X_train_finish.to_csv(path_phillip + \"X_train_finish.csv\", index=False)\n",
    "y_train_finish.to_csv(path_phillip + \"y_train_finish.csv\", index=False)\n",
    "X_test_finish.to_csv(path_phillip + \"X_test_finish.csv\", index=False)\n",
    "y_test_finish.to_csv(path_phillip + \"y_test_finish.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56bc686-4e50-4643-b492-77db44fb36bd",
   "metadata": {
    "editable": true,
    "id": "2Q-tuNkZ6lop",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder  # Import LabelEncoder\n",
    "\n",
    "# Create a new LabelEncoder specifically for the target variable\n",
    "target_le = LabelEncoder()\n",
    "\n",
    "# Fit the target encoder on the training labels\n",
    "y_train_encoded = target_le.fit_transform(y_train_finish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af198163-e3ef-491a-b50b-7655ae01495a",
   "metadata": {
    "editable": true,
    "id": "kCKReKWm7lnj",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert categorical columns in X_train_finish and X_test_finish to numerical values\n",
    "# Assuming X_train_finish and X_test_finish are pandas DataFrames\n",
    "for column in X_train_finish.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()  # Create a new LabelEncoder for each column\n",
    "\n",
    "    # Fit on the combined unique values from both train and test data\n",
    "    all_values = pd.concat([X_train_finish[column], X_test_finish[column]]).unique()\n",
    "    le.fit(all_values)\n",
    "\n",
    "    X_train_finish[column] = le.transform(X_train_finish[column])  # Encode the training data\n",
    "    X_test_finish[column] = le.transform(X_test_finish[column])  # Encode the test data# Convert categorical columns in X_train_finish and X_test_finish to numerical values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7633c61-712c-4e50-a53a-7b9fbd755cfd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "editable": true,
    "id": "0rYO1gWEAW2j",
    "outputId": "1932eb53-493f-4609-b366-be421d3dcbb3",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test_finish[['BootcampName']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce48181-5a79-49d5-b390-dda942a85c6a",
   "metadata": {
    "editable": true,
    "id": "LKFd5atN7rtZ",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the target encoder to transform the test labels, handling unseen labels\n",
    "try:\n",
    "    y_test_encoded = target_le.transform(y_test_finish)  # This will raise an error if unseen labels exist\n",
    "except ValueError as e:\n",
    "    print(f\"Warning: {e}. Encoding unseen labels as -1.\")\n",
    "    # Get unseen labels and add them to the encoder\n",
    "    unseen_labels = set(y_test_finish) - set(target_le.classes_)\n",
    "    for label in unseen_labels:\n",
    "        target_le.classes_ = np.append(target_le.classes_, label)\n",
    "    y_test_encoded = target_le.transform(y_test_finish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e4b766-b6fc-4b63-9bfc-965399c29e1d",
   "metadata": {
    "editable": true,
    "id": "hqbtgs8L7vM8",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Creating an XGBoost classifier\n",
    "model = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296f66ee-131d-4c3f-844e-410b991f2de2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "editable": true,
    "id": "YwLAQTcW7xY8",
    "outputId": "19198d45-bd3e-4f8d-e5c2-cb235b579c97",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training the model on the training data\n",
    "model.fit(X_train_finish, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733c9460-8767-4900-8a45-59eb349c8522",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "editable": true,
    "id": "h4fqIao_8dvf",
    "outputId": "ee6db073-62a1-4fd2-82b5-85d0b0586bfb",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_finish[['BootcampName']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24571c3c-f4ef-41c2-b2eb-186f7e31d6f9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "editable": true,
    "id": "fQ-4GSsU8c16",
    "outputId": "7ddff1d0-63fa-4ce6-cecd-423627e15faf",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test_finish[['BootcampName']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dad94e-c812-43f3-a3ed-57197fb7cc8b",
   "metadata": {
    "editable": true,
    "id": "URlxL43R70R_",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Making predictions on the test set\n",
    "predictions = model.predict(X_test_finish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72579e7-605a-439a-ae3b-d798943927ba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "d168e561-fb64-4fd5-aa47-0878f1a9be83",
    "outputId": "d6877f1c-58fb-4c49-c8c3-a699a0e6dc06",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate the model\n",
    "print(f'Training Score: {model.score(X_train_finish, y_train_encoded)}')\n",
    "print(f'Testing Score: {model.score(X_test_finish, y_test_encoded)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedcbde5-0cac-41c2-a11e-9463c38746d1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a loop to vary the max_depth parameter\n",
    "# Make sure to record the train and test scores \n",
    "# for each pass.\n",
    "\n",
    "# Depths should span from 1 up to 40 in steps of 2\n",
    "depths = range(1, 20, 2)\n",
    "\n",
    "# The scores dataframe will hold depths and scores\n",
    "# to make plotting easy\n",
    "scores = {'train': [], 'test': [], 'depth': []}\n",
    "\n",
    "# Loop through each depth (this will take time to run)\n",
    "for depth in depths:\n",
    "    clf = xgb.XGBClassifier(max_depth=depth)\n",
    "    clf.fit(X_train_finish, y_train_finish)\n",
    "\n",
    "    train_score = clf.score(X_train_finish, y_train_finish)\n",
    "    test_score = clf.score(X_test_finish, y_test_finish)\n",
    "\n",
    "    scores['depth'].append(depth)\n",
    "    scores['train'].append(train_score)\n",
    "    scores['test'].append(test_score)\n",
    "\n",
    "# Create a dataframe from the scores dictionary and\n",
    "# set the index to depth\n",
    "scores_df = pd.DataFrame(scores).set_index('depth')\n",
    "\n",
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bc3594-dcc2-4d83-adf9-596aa19fe9ec",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the scores dataframe with the plot method\n",
    "scores_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47db665-338d-4599-a7f9-01459a566fe8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "984ec748-aaf4-449e-a574-07ea47185a98",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
